{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd472e45",
   "metadata": {},
   "source": [
    "### Objective of the NB\n",
    "\n",
    "To practice clustering and classification algorithms with the datasets like amazon, WB indicators. \n",
    "\n",
    "Continue the study with NLP related analysis using the Quora answers\n",
    "\n",
    "- I have to still understand, how to write out the model and load the model\n",
    "\n",
    "- Need to understand how the feature selection works\n",
    "\n",
    "- Practice setting up KPI based on the data Analysis and modeling\n",
    "\n",
    "- Try to get hands on real world manufacturing data, and do the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18100bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50a90cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 12:49:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "22/11/29 12:49:32 INFO SharedState: Warehouse path is 'file:/run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/spark-warehouse'.\n",
      "22/11/29 12:49:35 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "#always initiate the spark session with all the connectivity that is \n",
    "#available in the environment you are workin\n",
    "sparkSQL = SparkSession.builder.appName(\"clustClass\") \\\n",
    "                .config('spark.jars',\"/usr/share/java/postgresql-42.2.26.jar\") \\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25110b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writingCSVFiletoDatabase(session, csvFile,dbName,dbTableName):\n",
    "    \n",
    "    fileSparkDF = session.read.csv(csvFile,inferSchema=True,header=True)\n",
    "    try:\n",
    "        fileSparkDF.write \\\n",
    "                    .format('jdbc') \\\n",
    "                    .option(\"url\", f\"jdbc:postgresql://localhost:5432/{dbName}\") \\\n",
    "                    .option('dbtable', dbTableName) \\\n",
    "                    .option('user','postgres') \\\n",
    "                    .option('password', 1234) \\\n",
    "                    .option('driver','org.postgresql.Driver') \\\n",
    "                    .save(mode='overwrite')\n",
    "        print('Write Complete')\n",
    "    except Exception as e:\n",
    "        print(f'Write errored out due to {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1aeac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For writing the data to db, the spark session\n",
    "def writingSparkDFtoDatabase(sparkDF,dbName,dbTableName):\n",
    "    \n",
    "    try:\n",
    "        sparkDF.write \\\n",
    "                    .format('jdbc') \\\n",
    "                    .option(\"url\", f\"jdbc:postgresql://localhost:5432/{dbName}\") \\\n",
    "                    .option('dbtable', dbTableName) \\\n",
    "                    .option('user','postgres') \\\n",
    "                    .option('password', 1234) \\\n",
    "                    .option('driver','org.postgresql.Driver') \\\n",
    "                    .save(mode='overwrite')\n",
    "        print('Write Complete')\n",
    "    except Exception as e:\n",
    "        print(f'Write errored out due to {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08bc7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkreader = sparkSQL.read\n",
    "sparkctxt = sparkSQL.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1777ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "externalData = \"externalData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7783e00a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 13:08:21 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 1 paths.\n",
      "22/11/29 13:08:21 INFO InMemoryFileIndex: It took 3 ms to list leaf files for 1 paths.\n",
      "22/11/29 13:08:21 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 13:08:21 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#73, None)) > 0)\n",
      "22/11/29 13:08:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "22/11/29 13:08:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 350.4 KiB, free 364.8 MiB)\n",
      "22/11/29 13:08:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 364.8 MiB)\n",
      "22/11/29 13:08:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.17.0.1:38511 (size: 34.0 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:08:21 INFO SparkContext: Created broadcast 6 from csv at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:08:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 13:08:21 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 13:08:21 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 11.8 KiB, free 364.8 MiB)\n",
      "22/11/29 13:08:21 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 364.8 MiB)\n",
      "22/11/29 13:08:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.17.0.1:38511 (size: 5.9 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:08:21 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 13:08:21 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "22/11/29 13:08:21 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 13:08:21 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)\n",
      "22/11/29 13:08:21 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 13:08:21 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 1730 bytes result sent to driver\n",
      "22/11/29 13:08:21 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 33 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 13:08:21 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "22/11/29 13:08:21 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 0.052 s\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 13:08:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.058150 s\n",
      "22/11/29 13:08:21 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 13:08:21 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 13:08:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>\n",
      "22/11/29 13:08:21 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 350.4 KiB, free 364.4 MiB)\n",
      "22/11/29 13:08:21 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 364.4 MiB)\n",
      "22/11/29 13:08:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.17.0.1:38511 (size: 34.0 KiB, free: 366.1 MiB)\n",
      "22/11/29 13:08:21 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:08:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 13:08:21 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Got job 4 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Final stage: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 13:08:21 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 25.1 KiB, free 364.4 MiB)\n",
      "22/11/29 13:08:21 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.9 KiB, free 364.4 MiB)\n",
      "22/11/29 13:08:21 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.17.0.1:38511 (size: 11.9 KiB, free: 366.1 MiB)\n",
      "22/11/29 13:08:21 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 13:08:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 13:08:21 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "22/11/29 13:08:21 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 13:08:21 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)\n",
      "22/11/29 13:08:21 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 13:08:22 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.17.0.1:38511 in memory (size: 5.5 KiB, free: 366.1 MiB)\n",
      "22/11/29 13:08:22 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.17.0.1:38511 in memory (size: 34.0 KiB, free: 366.1 MiB)\n",
      "22/11/29 13:08:22 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.17.0.1:38511 in memory (size: 34.0 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:08:22 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.17.0.1:38511 in memory (size: 5.9 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:08:22 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 1778 bytes result sent to driver\n",
      "22/11/29 13:08:22 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 739 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 13:08:22 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "22/11/29 13:08:22 INFO DAGScheduler: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0) finished in 0.817 s\n",
      "22/11/29 13:08:22 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 13:08:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "22/11/29 13:08:22 INFO DAGScheduler: Job 4 finished: csv at NativeMethodAccessorImpl.java:0, took 0.830710 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Reading in the amazonRA encoded data, that was prepared using the \n",
    "#amazon_delivery_analysis.ipynb\n",
    "\n",
    "amazonEncoded = sparkreader.csv(externalData+\"amazonRA_encoded.csv\",\n",
    "                               inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "995bbd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 13:06:07 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 13:06:07 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 13:06:07 INFO FileSourceStrategy: Output Data Schema: struct<>\n",
      "22/11/29 13:06:07 INFO CodeGenerator: Code generated in 24.195704 ms\n",
      "22/11/29 13:06:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 350.0 KiB, free 365.2 MiB)\n",
      "22/11/29 13:06:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 365.2 MiB)\n",
      "22/11/29 13:06:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.17.0.1:38511 (size: 34.0 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:06:07 INFO SparkContext: Created broadcast 3 from count at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:06:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 13:06:07 INFO DAGScheduler: Registering RDD 13 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0\n",
      "22/11/29 13:06:07 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 13:06:07 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 13:06:07 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 13:06:07 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 13:06:07 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 13:06:07 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.5 KiB, free 365.1 MiB)\n",
      "22/11/29 13:06:07 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 365.1 MiB)\n",
      "22/11/29 13:06:07 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.17.0.1:38511 (size: 8.3 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:06:07 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 13:06:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 13:06:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "22/11/29 13:06:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 13:06:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "22/11/29 13:06:08 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 13:06:08 INFO CodeGenerator: Code generated in 16.659466 ms\n",
      "22/11/29 13:06:08 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1965 bytes result sent to driver\n",
      "22/11/29 13:06:08 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 312 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 13:06:08 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "22/11/29 13:06:08 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.416 s\n",
      "22/11/29 13:06:08 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 13:06:08 INFO DAGScheduler: running: Set()\n",
      "22/11/29 13:06:08 INFO DAGScheduler: waiting: Set()\n",
      "22/11/29 13:06:08 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 13:06:08 INFO CodeGenerator: Code generated in 23.449475 ms\n",
      "22/11/29 13:06:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:06:08 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 13:06:08 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 13:06:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)\n",
      "22/11/29 13:06:08 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 13:06:08 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 13:06:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.1 KiB, free 365.1 MiB)\n",
      "22/11/29 13:06:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 365.1 MiB)\n",
      "22/11/29 13:06:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.17.0.1:38511 (size: 5.5 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:06:08 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 13:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 13:06:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "22/11/29 13:06:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "22/11/29 13:06:08 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)\n",
      "22/11/29 13:06:08 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 13:06:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms\n",
      "22/11/29 13:06:08 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 2699 bytes result sent to driver\n",
      "22/11/29 13:06:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 150 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 13:06:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "22/11/29 13:06:08 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.207 s\n",
      "22/11/29 13:06:08 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 13:06:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "22/11/29 13:06:08 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.253531 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10669"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 13:06:08 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.17.0.1:38511 in memory (size: 5.9 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:06:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.17.0.1:38511 in memory (size: 8.3 KiB, free: 366.2 MiB)\n"
     ]
    }
   ],
   "source": [
    "amazonEncoded.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a732bc86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Delivery_person_ID: string (nullable = true)\n",
      " |-- Type_of_Vehicle: string (nullable = true)\n",
      " |-- DeliveryPersonAge: double (nullable = true)\n",
      " |-- DeliveryPersonRatings: double (nullable = true)\n",
      " |-- TypeOfVehicle: double (nullable = true)\n",
      " |-- DeliveryPersonID: double (nullable = true)\n",
      " |-- Restaurant_latitude: double (nullable = true)\n",
      " |-- Restaurant_longitude: double (nullable = true)\n",
      " |-- Delivery_location_latitude: double (nullable = true)\n",
      " |-- Delivery_location_longitude: double (nullable = true)\n",
      " |-- Order_Date: string (nullable = true)\n",
      " |-- Weather_idx: double (nullable = true)\n",
      " |-- Road_traffic_density_idx: double (nullable = true)\n",
      " |-- Type_of_order_idx: double (nullable = true)\n",
      " |-- multiple_deliveries_idx: double (nullable = true)\n",
      " |-- IntervalPickup: integer (nullable = true)\n",
      "\n",
      "22/11/29 13:18:22 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.17.0.1:38511 in memory (size: 34.0 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:18:22 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.17.0.1:38511 in memory (size: 11.9 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:18:22 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.17.0.1:38511 in memory (size: 34.0 KiB, free: 366.3 MiB)\n",
      "22/11/29 13:18:22 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.17.0.1:38511 in memory (size: 34.0 KiB, free: 366.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "amazonEncoded.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8799a7d3",
   "metadata": {},
   "source": [
    "Thinking of a way to create the clustering model around the amazon data. The road traffic density, restaurant location and delivery locations can be used in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18aae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 13:47:52 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 13:47:52 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 13:47:52 INFO FileSourceStrategy: Output Data Schema: struct<Road_traffic_density_idx: double>\n",
      "22/11/29 13:47:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "22/11/29 13:47:52 INFO CodeGenerator: Code generated in 52.389035 ms\n",
      "22/11/29 13:47:52 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 350.3 KiB, free 366.0 MiB)\n",
      "22/11/29 13:47:52 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 365.9 MiB)\n",
      "22/11/29 13:47:52 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.3 MiB)\n",
      "22/11/29 13:47:52 INFO SparkContext: Created broadcast 10 from showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:47:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 13:47:52 INFO DAGScheduler: Registering RDD 30 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 1\n",
      "22/11/29 13:47:52 INFO DAGScheduler: Got map stage job 5 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 13:47:52 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (showString at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 13:47:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 13:47:52 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 13:47:52 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 13:47:52 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 30.7 KiB, free 365.9 MiB)\n",
      "22/11/29 13:47:52 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 365.9 MiB)\n",
      "22/11/29 13:47:52 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.17.0.1:38511 (size: 14.7 KiB, free: 366.3 MiB)\n",
      "22/11/29 13:47:52 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 13:47:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 13:47:52 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "22/11/29 13:47:52 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 13:47:52 INFO Executor: Running task 0.0 in stage 6.0 (TID 5)\n",
      "22/11/29 13:47:52 INFO CodeGenerator: Code generated in 25.299259 ms\n",
      "22/11/29 13:47:52 INFO CodeGenerator: Code generated in 17.131776 ms\n",
      "22/11/29 13:47:53 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 13:47:53 INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 2725 bytes result sent to driver\n",
      "22/11/29 13:47:53 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 421 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 13:47:53 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "22/11/29 13:47:53 INFO DAGScheduler: ShuffleMapStage 6 (showString at NativeMethodAccessorImpl.java:0) finished in 0.452 s\n",
      "22/11/29 13:47:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 13:47:53 INFO DAGScheduler: running: Set()\n",
      "22/11/29 13:47:53 INFO DAGScheduler: waiting: Set()\n",
      "22/11/29 13:47:53 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 13:47:53 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "22/11/29 13:47:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "22/11/29 13:47:53 INFO CodeGenerator: Code generated in 38.40914 ms\n",
      "22/11/29 13:47:53 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:47:53 INFO DAGScheduler: Got job 6 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 13:47:53 INFO DAGScheduler: Final stage: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 13:47:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\n",
      "22/11/29 13:47:53 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 13:47:53 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[33] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 13:47:53 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 35.5 KiB, free 365.8 MiB)\n",
      "22/11/29 13:47:53 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 365.8 MiB)\n",
      "22/11/29 13:47:53 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.17.0.1:38511 (size: 17.0 KiB, free: 366.2 MiB)\n",
      "22/11/29 13:47:53 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 13:47:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[33] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 13:47:53 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "22/11/29 13:47:53 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "22/11/29 13:47:53 INFO Executor: Running task 0.0 in stage 8.0 (TID 6)\n",
      "22/11/29 13:47:53 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 13:47:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms\n",
      "22/11/29 13:47:53 INFO Executor: Finished task 0.0 in stage 8.0 (TID 6). 3817 bytes result sent to driver\n",
      "22/11/29 13:47:53 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 58 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 13:47:53 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "22/11/29 13:47:53 INFO DAGScheduler: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0) finished in 0.076 s\n",
      "22/11/29 13:47:53 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 13:47:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished\n",
      "22/11/29 13:47:53 INFO DAGScheduler: Job 6 finished: showString at NativeMethodAccessorImpl.java:0, took 0.091915 s\n",
      "22/11/29 13:47:53 INFO CodeGenerator: Code generated in 34.664701 ms\n",
      "+------------------------+\n",
      "|Road_traffic_density_idx|\n",
      "+------------------------+\n",
      "|                     0.0|\n",
      "|                     1.0|\n",
      "|                     4.0|\n",
      "|                     3.0|\n",
      "|                     2.0|\n",
      "+------------------------+\n",
      "\n",
      "22/11/29 13:48:22 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.17.0.1:38511 in memory (size: 34.1 KiB, free: 366.3 MiB)\n",
      "22/11/29 13:48:22 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.17.0.1:38511 in memory (size: 17.0 KiB, free: 366.3 MiB)\n",
      "22/11/29 13:48:22 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.17.0.1:38511 in memory (size: 14.7 KiB, free: 366.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "amazonEncoded.select(\"Road_traffic_density_idx\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81cf1cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 13:51:03 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 13:51:03 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 13:51:03 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 13:51:03 INFO CodeGenerator: Code generated in 30.931846 ms\n",
      "22/11/29 13:51:03 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 350.3 KiB, free 366.0 MiB)\n",
      "22/11/29 13:51:03 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 365.9 MiB)\n",
      "22/11/29 13:51:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.3 MiB)\n",
      "22/11/29 13:51:03 INFO SparkContext: Created broadcast 13 from showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:51:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 13:51:03 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 13:51:03 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 13:51:03 INFO DAGScheduler: Final stage: ResultStage 9 (showString at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 13:51:03 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 13:51:03 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 13:51:03 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[37] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 13:51:04 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 17.3 KiB, free 365.9 MiB)\n",
      "22/11/29 13:51:04 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 365.9 MiB)\n",
      "22/11/29 13:51:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.17.0.1:38511 (size: 7.9 KiB, free: 366.3 MiB)\n",
      "22/11/29 13:51:04 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 13:51:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[37] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 13:51:04 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "22/11/29 13:51:04 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 13:51:04 INFO Executor: Running task 0.0 in stage 9.0 (TID 7)\n",
      "22/11/29 13:51:04 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 13:51:04 INFO CodeGenerator: Code generated in 22.020947 ms\n",
      "22/11/29 13:51:04 INFO Executor: Finished task 0.0 in stage 9.0 (TID 7). 1700 bytes result sent to driver\n",
      "22/11/29 13:51:04 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 85 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 13:51:04 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "22/11/29 13:51:04 INFO DAGScheduler: ResultStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 0.188 s\n",
      "22/11/29 13:51:04 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 13:51:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished\n",
      "22/11/29 13:51:04 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0.194592 s\n",
      "22/11/29 13:51:04 INFO CodeGenerator: Code generated in 24.96684 ms\n",
      "+-----+-------------------+--------------------+---------------------------+--------------------------+-----------+-----------------+\n",
      "|label|Restaurant_latitude|Restaurant_longitude|Delivery_location_longitude|Delivery_location_latitude|Weather_idx|Type_of_order_idx|\n",
      "+-----+-------------------+--------------------+---------------------------+--------------------------+-----------+-----------------+\n",
      "|  1.0|          12.975377|           77.696664|                  77.806664|                 13.085377|        1.0|              2.0|\n",
      "|  1.0|          26.911378|           75.789034|                  75.879034|                 27.001378|        4.0|              0.0|\n",
      "+-----+-------------------+--------------------+---------------------------+--------------------------+-----------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusteringData = amazonEncoded.select(col(\"Road_traffic_density_idx\").alias('label'),\n",
    "                                     \"Restaurant_latitude\",\"Restaurant_longitude\",\n",
    "                                     \"Delivery_location_longitude\",\"Delivery_location_latitude\",\n",
    "                                     \"Weather_idx\",\"Type_of_order_idx\")\n",
    "clusteringData.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aedd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c61bb",
   "metadata": {},
   "source": [
    "### Opportunity to do both Classification and Clustering is opening up\n",
    "\n",
    "The traffic density point would be linked with busy part of the cities, so that can be inferred by clustering and finding the centers\n",
    "\n",
    "The traffic can be predicted based on the data that is available, and the delivery time can be estimated. The data can be used in different ways "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b0186ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterAssy = VectorAssembler(inputCols=[\"Type_of_order_idx\",\"Weather_idx\",\n",
    "                                        \"Delivery_location_latitude\",\"Delivery_location_longitude\",\n",
    "                                        \"Restaurant_longitude\",\"Restaurant_latitude\"],\n",
    "                             outputCol=\"features\")\n",
    "kmeansCluster = KMeans(featuresCol=\"features\",k=5)\n",
    "clusterPipe = Pipeline(stages=[clusterAssy,kmeansCluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d8e8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train,test) = amazonEncoded.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "270178b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:14:50 INFO Instrumentation: [42aef167] Stage class: KMeans\n",
      "22/11/29 14:14:50 INFO Instrumentation: [42aef167] Stage uid: KMeans_ce8a75624c79\n",
      "22/11/29 14:14:50 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:14:50 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:14:50 INFO FileSourceStrategy: Output Data Schema: struct<ID: string, Delivery_person_ID: string, Type_of_Vehicle: string, DeliveryPersonAge: double, DeliveryPersonRatings: double ... 15 more fields>\n",
      "22/11/29 14:14:50 INFO CodeGenerator: Code generated in 34.01239 ms\n",
      "22/11/29 14:14:50 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 350.3 KiB, free 364.7 MiB)\n",
      "22/11/29 14:14:50 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 364.7 MiB)\n",
      "22/11/29 14:14:50 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:14:50 INFO SparkContext: Created broadcast 51 from rdd at Instrumentation.scala:62\n",
      "22/11/29 14:14:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:14:50 INFO Instrumentation: [42aef167] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n",
      "22/11/29 14:14:50 INFO Instrumentation: [42aef167] {\"featuresCol\":\"features\",\"k\":5}\n",
      "22/11/29 14:14:50 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:14:50 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:14:50 INFO FileSourceStrategy: Output Data Schema: struct<ID: string, Delivery_person_ID: string, Type_of_Vehicle: string, DeliveryPersonAge: double, DeliveryPersonRatings: double ... 15 more fields>\n",
      "22/11/29 14:14:50 INFO CodeGenerator: Code generated in 33.168664 ms\n",
      "22/11/29 14:14:50 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 350.3 KiB, free 364.4 MiB)\n",
      "22/11/29 14:14:50 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 364.3 MiB)\n",
      "22/11/29 14:14:50 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:14:50 INFO SparkContext: Created broadcast 52 from rdd at KMeans.scala:350\n",
      "22/11/29 14:14:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:14:50 INFO SparkContext: Starting job: takeSample at KMeans.scala:384\n",
      "22/11/29 14:14:50 INFO DAGScheduler: Got job 24 (takeSample at KMeans.scala:384) with 1 output partitions\n",
      "22/11/29 14:14:50 INFO DAGScheduler: Final stage: ResultStage 31 (takeSample at KMeans.scala:384)\n",
      "22/11/29 14:14:50 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:14:50 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:14:50 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[112] at map at KMeans.scala:223), which has no missing parents\n",
      "22/11/29 14:14:50 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 53.1 KiB, free 364.3 MiB)\n",
      "22/11/29 14:14:50 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 364.3 MiB)\n",
      "22/11/29 14:14:50 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.17.0.1:38511 (size: 22.7 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:14:50 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[112] at map at KMeans.scala:223) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:50 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:50 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 28) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5289 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:50 INFO Executor: Running task 0.0 in stage 31.0 (TID 28)\n",
      "22/11/29 14:14:50 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:14:51 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.17.0.1:38511 in memory (size: 27.0 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.17.0.1:38511 in memory (size: 34.1 KiB, free: 366.1 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 31:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:14:51 INFO MemoryStore: Block rdd_112_0 stored as values in memory (estimated size 838.7 KiB, free 363.9 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added rdd_112_0 in memory on 172.17.0.1:38511 (size: 838.7 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:14:51 INFO Executor: Finished task 0.0 in stage 31.0 (TID 28). 1892 bytes result sent to driver\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 28) in 552 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:51 INFO DAGScheduler: ResultStage 31 (takeSample at KMeans.scala:384) finished in 0.565 s\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 24 finished: takeSample at KMeans.scala:384, took 0.569827 s\n",
      "22/11/29 14:14:51 INFO SparkContext: Starting job: takeSample at KMeans.scala:384\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Got job 25 (takeSample at KMeans.scala:384) with 1 output partitions\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Final stage: ResultStage 32 (takeSample at KMeans.scala:384)\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting ResultStage 32 (PartitionwiseSampledRDD[114] at takeSample at KMeans.scala:384), which has no missing parents\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 53.8 KiB, free 363.9 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 363.8 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.17.0.1:38511 (size: 23.1 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:14:51 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (PartitionwiseSampledRDD[114] at takeSample at KMeans.scala:384) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 29) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:51 INFO Executor: Running task 0.0 in stage 32.0 (TID 29)\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:51 INFO Executor: Finished task 0.0 in stage 32.0 (TID 29). 3820 bytes result sent to driver\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 29) in 14 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:51 INFO DAGScheduler: ResultStage 32 (takeSample at KMeans.scala:384) finished in 0.023 s\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 25 finished: takeSample at KMeans.scala:384, took 0.026598 s\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 160.0 B, free 363.8 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 316.0 B, free 363.8 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.17.0.1:38511 (size: 316.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:14:51 INFO SparkContext: Created broadcast 55 from broadcast at KMeans.scala:398\n",
      "22/11/29 14:14:51 INFO SparkContext: Starting job: sum at KMeans.scala:404\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Got job 26 (sum at KMeans.scala:404) with 1 output partitions\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Final stage: ResultStage 33 (sum at KMeans.scala:404)\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[116] at map at KMeans.scala:401), which has no missing parents\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 54.4 KiB, free 363.8 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 363.8 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.17.0.1:38511 (size: 23.1 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:14:51 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[116] at map at KMeans.scala:401) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 30) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5321 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:51 INFO Executor: Running task 0.0 in stage 33.0 (TID 30)\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block rdd_116_0 stored as values in memory (estimated size 58.6 KiB, free 363.7 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added rdd_116_0 in memory on 172.17.0.1:38511 (size: 58.6 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:51 INFO Executor: Finished task 0.0 in stage 33.0 (TID 30). 1808 bytes result sent to driver\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 30) in 62 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:51 INFO DAGScheduler: ResultStage 33 (sum at KMeans.scala:404) finished in 0.082 s\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 26 finished: sum at KMeans.scala:404, took 0.087347 s\n",
      "22/11/29 14:14:51 INFO MapPartitionsRDD: Removing RDD 113 from persistence list\n",
      "22/11/29 14:14:51 INFO BlockManager: Removing RDD 113\n",
      "22/11/29 14:14:51 INFO SparkContext: Starting job: collect at KMeans.scala:409\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Got job 27 (collect at KMeans.scala:409) with 1 output partitions\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Final stage: ResultStage 34 (collect at KMeans.scala:409)\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[118] at mapPartitionsWithIndex at KMeans.scala:409), which has no missing parents\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 54.8 KiB, free 363.6 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 23.3 KiB, free 363.6 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.17.0.1:38511 (size: 23.3 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:51 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[118] at mapPartitionsWithIndex at KMeans.scala:409) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 31) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5353 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:51 INFO Executor: Running task 0.0 in stage 34.0 (TID 31)\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_116_0 locally\n",
      "22/11/29 14:14:51 INFO Executor: Finished task 0.0 in stage 34.0 (TID 31). 2869 bytes result sent to driver\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 31) in 17 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:51 INFO DAGScheduler: ResultStage 34 (collect at KMeans.scala:409) finished in 0.041 s\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 27 finished: collect at KMeans.scala:409, took 0.050369 s\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 1200.0 B, free 363.6 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 597.0 B, free 363.6 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.17.0.1:38511 (size: 597.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:51 INFO SparkContext: Created broadcast 58 from broadcast at KMeans.scala:398\n",
      "22/11/29 14:14:51 INFO SparkContext: Starting job: sum at KMeans.scala:404\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Got job 28 (sum at KMeans.scala:404) with 1 output partitions\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Final stage: ResultStage 35 (sum at KMeans.scala:404)\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[120] at map at KMeans.scala:401), which has no missing parents\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 54.8 KiB, free 363.6 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 23.3 KiB, free 363.5 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.17.0.1:38511 (size: 23.3 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:51 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[120] at map at KMeans.scala:401) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 32) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5353 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:51 INFO Executor: Running task 0.0 in stage 35.0 (TID 32)\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_116_0 locally\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block rdd_120_0 stored as values in memory (estimated size 58.6 KiB, free 363.5 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added rdd_120_0 in memory on 172.17.0.1:38511 (size: 58.6 KiB, free: 365.1 MiB)\n",
      "22/11/29 14:14:51 INFO Executor: Finished task 0.0 in stage 35.0 (TID 32). 1808 bytes result sent to driver\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 32) in 40 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:51 INFO DAGScheduler: ResultStage 35 (sum at KMeans.scala:404) finished in 0.056 s\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 28 finished: sum at KMeans.scala:404, took 0.061882 s\n",
      "22/11/29 14:14:51 INFO MapPartitionsRDD: Removing RDD 116 from persistence list\n",
      "22/11/29 14:14:51 INFO BlockManager: Removing RDD 116\n",
      "22/11/29 14:14:51 INFO SparkContext: Starting job: collect at KMeans.scala:409\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Got job 29 (collect at KMeans.scala:409) with 1 output partitions\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Final stage: ResultStage 36 (collect at KMeans.scala:409)\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[122] at mapPartitionsWithIndex at KMeans.scala:409), which has no missing parents\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 55.2 KiB, free 363.5 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 363.5 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.17.0.1:38511 (size: 23.4 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:51 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[122] at mapPartitionsWithIndex at KMeans.scala:409) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 33) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5385 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:51 INFO Executor: Running task 0.0 in stage 36.0 (TID 33)\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_120_0 locally\n",
      "22/11/29 14:14:51 INFO Executor: Finished task 0.0 in stage 36.0 (TID 33). 3474 bytes result sent to driver\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 33) in 14 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:51 INFO DAGScheduler: ResultStage 36 (collect at KMeans.scala:409) finished in 0.022 s\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Job 29 finished: collect at KMeans.scala:409, took 0.027042 s\n",
      "22/11/29 14:14:51 INFO MapPartitionsRDD: Removing RDD 120 from persistence list\n",
      "22/11/29 14:14:51 INFO TorrentBroadcast: Destroying Broadcast(55) (from destroy at KMeans.scala:419)\n",
      "22/11/29 14:14:51 INFO BlockManager: Removing RDD 120\n",
      "22/11/29 14:14:51 INFO TorrentBroadcast: Destroying Broadcast(58) (from destroy at KMeans.scala:419)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:14:51 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.17.0.1:38511 in memory (size: 597.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 3.2 KiB, free 363.5 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.17.0.1:38511 in memory (size: 316.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 1574.0 B, free 363.5 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.17.0.1:38511 (size: 1574.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:51 INFO SparkContext: Created broadcast 61 from broadcast at KMeans.scala:429\n",
      "22/11/29 14:14:51 INFO SparkContext: Starting job: countByValue at KMeans.scala:432\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Registering RDD 125 (countByValue at KMeans.scala:432) as input to shuffle 7\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Got job 30 (countByValue at KMeans.scala:432) with 1 output partitions\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Final stage: ResultStage 38 (countByValue at KMeans.scala:432)\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[125] at countByValue at KMeans.scala:432), which has no missing parents\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 55.7 KiB, free 363.5 MiB)\n",
      "22/11/29 14:14:51 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 363.4 MiB)\n",
      "22/11/29 14:14:51 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.17.0.1:38511 (size: 23.9 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:51 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[125] at countByValue at KMeans.scala:432) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:51 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:51 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 34) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:51 INFO Executor: Running task 0.0 in stage 37.0 (TID 34)\n",
      "22/11/29 14:14:51 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 37.0 (TID 34). 2090 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 34) in 67 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: ShuffleMapStage 37 (countByValue at KMeans.scala:432) finished in 0.083 s\n",
      "22/11/29 14:14:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:14:52 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: waiting: Set(ResultStage 38)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ResultStage 38 (ShuffledRDD[126] at countByValue at KMeans.scala:432), which has no missing parents\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 5.2 KiB, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.17.0.1:38511 (size: 3.0 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (ShuffledRDD[126] at countByValue at KMeans.scala:432) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 35) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 38.0 (TID 35)\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 38.0 (TID 35). 2279 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 35) in 15 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: ResultStage 38 (countByValue at KMeans.scala:432) finished in 0.026 s\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 30 finished: countByValue at KMeans.scala:432, took 0.115535 s\n",
      "22/11/29 14:14:52 INFO TorrentBroadcast: Destroying Broadcast(61) (from destroy at KMeans.scala:434)\n",
      "22/11/29 14:14:52 INFO LocalKMeans: Local KMeans++ converged in 3 iterations.\n",
      "22/11/29 14:14:52 INFO KMeans: Initialization with k-means|| took 1.170 seconds.\n",
      "22/11/29 14:14:52 INFO Instrumentation: [42aef167] {\"numFeatures\":6}\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 624.0 B, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 578.0 B, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.17.0.1:38511 in memory (size: 1574.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.17.0.1:38511 (size: 578.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 64 from broadcast at KMeans.scala:279\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 176.0 B, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.17.0.1:38511 (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 65 from broadcast at KMeans.scala:289\n",
      "22/11/29 14:14:52 INFO SparkContext: Starting job: collectAsMap at KMeans.scala:315\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Registering RDD 127 (mapPartitions at KMeans.scala:294) as input to shuffle 8\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Got job 31 (collectAsMap at KMeans.scala:315) with 1 output partitions\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Final stage: ResultStage 40 (collectAsMap at KMeans.scala:315)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[127] at mapPartitions at KMeans.scala:294), which has no missing parents\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 55.0 KiB, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.17.0.1:38511 (size: 23.7 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[127] at mapPartitions at KMeans.scala:294) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 36) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 39.0 (TID 36)\n",
      "22/11/29 14:14:52 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 39.0 (TID 36). 2203 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 36) in 27 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: ShuffleMapStage 39 (mapPartitions at KMeans.scala:294) finished in 0.040 s\n",
      "22/11/29 14:14:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:14:52 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: waiting: Set(ResultStage 40)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ResultStage 40 (ShuffledRDD[128] at reduceByKey at KMeans.scala:315), which has no missing parents\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 4.8 KiB, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.17.0.1:38511 (size: 2.8 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (ShuffledRDD[128] at reduceByKey at KMeans.scala:315) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 37) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 40.0 (TID 37)\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 40.0 (TID 37). 2018 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 37) in 9 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: ResultStage 40 (collectAsMap at KMeans.scala:315) finished in 0.018 s\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 31 finished: collectAsMap at KMeans.scala:315, took 0.070489 s\n",
      "22/11/29 14:14:52 INFO Instrumentation: [42aef167] {\"numExamples\":7494}\n",
      "22/11/29 14:14:52 INFO Instrumentation: [42aef167] {\"sumOfWeights\":7494.0}\n",
      "22/11/29 14:14:52 INFO TorrentBroadcast: Destroying Broadcast(64) (from destroy at KMeans.scala:325)\n",
      "22/11/29 14:14:52 INFO TorrentBroadcast: Destroying Broadcast(65) (from destroy at KMeans.scala:326)\n",
      "22/11/29 14:14:52 INFO Instrumentation: [42aef167] {\"Cost@iter=0\":\"201545.99019035348\"}\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 624.0 B, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 575.0 B, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.17.0.1:38511 (size: 575.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 68 from broadcast at KMeans.scala:279\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 176.0 B, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.17.0.1:38511 in memory (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.17.0.1:38511 in memory (size: 578.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.17.0.1:38511 (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 69 from broadcast at KMeans.scala:289\n",
      "22/11/29 14:14:52 INFO SparkContext: Starting job: collectAsMap at KMeans.scala:315\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Registering RDD 129 (mapPartitions at KMeans.scala:294) as input to shuffle 9\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Got job 32 (collectAsMap at KMeans.scala:315) with 1 output partitions\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Final stage: ResultStage 42 (collectAsMap at KMeans.scala:315)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[129] at mapPartitions at KMeans.scala:294), which has no missing parents\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 55.0 KiB, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.17.0.1:38511 (size: 23.7 KiB, free: 365.1 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[129] at mapPartitions at KMeans.scala:294) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 38) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 41.0 (TID 38)\n",
      "22/11/29 14:14:52 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 41.0 (TID 38). 2203 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 38) in 18 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: ShuffleMapStage 41 (mapPartitions at KMeans.scala:294) finished in 0.030 s\n",
      "22/11/29 14:14:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:14:52 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: waiting: Set(ResultStage 42)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ResultStage 42 (ShuffledRDD[130] at reduceByKey at KMeans.scala:315), which has no missing parents\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 4.8 KiB, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.17.0.1:38511 (size: 2.8 KiB, free: 365.1 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (ShuffledRDD[130] at reduceByKey at KMeans.scala:315) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 39) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 42.0 (TID 39)\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 42.0 (TID 39). 2018 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 39) in 10 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: ResultStage 42 (collectAsMap at KMeans.scala:315) finished in 0.016 s\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 32 finished: collectAsMap at KMeans.scala:315, took 0.052789 s\n",
      "22/11/29 14:14:52 INFO TorrentBroadcast: Destroying Broadcast(68) (from destroy at KMeans.scala:325)\n",
      "22/11/29 14:14:52 INFO TorrentBroadcast: Destroying Broadcast(69) (from destroy at KMeans.scala:326)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.17.0.1:38511 in memory (size: 575.0 B, free: 365.1 MiB)\n",
      "22/11/29 14:14:52 INFO Instrumentation: [42aef167] {\"Cost@iter=1\":\"189368.06592439843\"}\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 624.0 B, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 568.0 B, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.17.0.1:38511 in memory (size: 250.0 B, free: 365.1 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.17.0.1:38511 (size: 568.0 B, free: 365.1 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 72 from broadcast at KMeans.scala:279\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 176.0 B, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.17.0.1:38511 (size: 250.0 B, free: 365.1 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 73 from broadcast at KMeans.scala:289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.17.0.1:38511 in memory (size: 2.8 KiB, free: 365.1 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Starting job: collectAsMap at KMeans.scala:315\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Registering RDD 131 (mapPartitions at KMeans.scala:294) as input to shuffle 10\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Got job 33 (collectAsMap at KMeans.scala:315) with 1 output partitions\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Final stage: ResultStage 44 (collectAsMap at KMeans.scala:315)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[131] at mapPartitions at KMeans.scala:294), which has no missing parents\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.17.0.1:38511 in memory (size: 23.9 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 55.0 KiB, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 363.3 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.17.0.1:38511 (size: 23.7 KiB, free: 365.1 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[131] at mapPartitions at KMeans.scala:294) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.17.0.1:38511 in memory (size: 23.1 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 40) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 43.0 (TID 40)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.17.0.1:38511 in memory (size: 2.8 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 43.0 (TID 40). 2203 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 40) in 23 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: ShuffleMapStage 43 (mapPartitions at KMeans.scala:294) finished in 0.039 s\n",
      "22/11/29 14:14:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:14:52 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: waiting: Set(ResultStage 44)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ResultStage 44 (ShuffledRDD[132] at reduceByKey at KMeans.scala:315), which has no missing parents\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.17.0.1:38511 in memory (size: 23.1 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 4.8 KiB, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 363.4 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.17.0.1:38511 (size: 2.8 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (ShuffledRDD[132] at reduceByKey at KMeans.scala:315) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.17.0.1:38511 in memory (size: 22.7 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 41) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 44.0 (TID 41)\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 44.0 (TID 41). 2018 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 41) in 8 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: ResultStage 44 (collectAsMap at KMeans.scala:315) finished in 0.018 s\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.17.0.1:38511 in memory (size: 23.7 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 33 finished: collectAsMap at KMeans.scala:315, took 0.064129 s\n",
      "22/11/29 14:14:52 INFO TorrentBroadcast: Destroying Broadcast(72) (from destroy at KMeans.scala:325)\n",
      "22/11/29 14:14:52 INFO TorrentBroadcast: Destroying Broadcast(73) (from destroy at KMeans.scala:326)\n",
      "22/11/29 14:14:52 INFO Instrumentation: [42aef167] {\"Cost@iter=2\":\"189178.65374037324\"}\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 624.0 B, free 363.6 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 568.0 B, free 363.6 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.17.0.1:38511 (size: 568.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 76 from broadcast at KMeans.scala:279\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 176.0 B, free 363.6 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.17.0.1:38511 in memory (size: 568.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.6 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.17.0.1:38511 (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 77 from broadcast at KMeans.scala:289\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.17.0.1:38511 in memory (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.17.0.1:38511 in memory (size: 23.3 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.17.0.1:38511 in memory (size: 23.7 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Starting job: collectAsMap at KMeans.scala:315\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Registering RDD 133 (mapPartitions at KMeans.scala:294) as input to shuffle 11\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Got job 34 (collectAsMap at KMeans.scala:315) with 1 output partitions\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Final stage: ResultStage 46 (collectAsMap at KMeans.scala:315)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 45)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[133] at mapPartitions at KMeans.scala:294), which has no missing parents\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 55.0 KiB, free 363.7 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 363.7 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.17.0.1:38511 (size: 23.7 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[133] at mapPartitions at KMeans.scala:294) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 42) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 45.0 (TID 42)\n",
      "22/11/29 14:14:52 INFO BlockManager: Removing RDD 120\n",
      "22/11/29 14:14:52 INFO BlockManager: Found block rdd_112_0 locally\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.17.0.1:38511 in memory (size: 23.3 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 45.0 (TID 42). 2203 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 42) in 23 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: ShuffleMapStage 45 (mapPartitions at KMeans.scala:294) finished in 0.034 s\n",
      "22/11/29 14:14:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:14:52 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: waiting: Set(ResultStage 46)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ResultStage 46 (ShuffledRDD[134] at reduceByKey at KMeans.scala:315), which has no missing parents\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 4.8 KiB, free 363.7 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 363.7 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.17.0.1:38511 (size: 2.8 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (ShuffledRDD[134] at reduceByKey at KMeans.scala:315) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 43) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 46.0 (TID 43)\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:14:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:14:52 INFO Executor: Finished task 0.0 in stage 46.0 (TID 43). 2018 bytes result sent to driver\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 43) in 9 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:52 INFO DAGScheduler: ResultStage 46 (collectAsMap at KMeans.scala:315) finished in 0.016 s\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Job 34 finished: collectAsMap at KMeans.scala:315, took 0.055586 s\n",
      "22/11/29 14:14:52 INFO TorrentBroadcast: Destroying Broadcast(76) (from destroy at KMeans.scala:325)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.17.0.1:38511 in memory (size: 3.0 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:14:52 INFO TorrentBroadcast: Destroying Broadcast(77) (from destroy at KMeans.scala:326)\n",
      "22/11/29 14:14:52 INFO Instrumentation: [42aef167] {\"Cost@iter=3\":\"189166.82917531478\"}\n",
      "22/11/29 14:14:52 INFO KMeans: Iterations took 0.405 seconds.\n",
      "22/11/29 14:14:52 INFO KMeans: KMeans converged in 4 iterations.\n",
      "22/11/29 14:14:52 INFO KMeans: The cost is 189166.82917531478.\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.17.0.1:38511 in memory (size: 250.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.17.0.1:38511 in memory (size: 568.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:14:52 INFO MapPartitionsRDD: Removing RDD 112 from persistence list\n",
      "22/11/29 14:14:52 INFO BlockManager: Removing RDD 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:14:52 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.17.0.1:38511 in memory (size: 23.4 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManager: Removing RDD 116\n",
      "22/11/29 14:14:52 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:14:52 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:14:52 INFO FileSourceStrategy: Output Data Schema: struct<ID: string, Delivery_person_ID: string, Type_of_Vehicle: string, DeliveryPersonAge: double, DeliveryPersonRatings: double ... 15 more fields>\n",
      "22/11/29 14:14:52 INFO CodeGenerator: Code generated in 49.718374 ms\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 350.3 KiB, free 364.3 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 364.3 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 80 from collect at ClusteringSummary.scala:49\n",
      "22/11/29 14:14:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Registering RDD 138 (collect at ClusteringSummary.scala:49) as input to shuffle 12\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Got map stage job 35 (collect at ClusteringSummary.scala:49) with 1 output partitions\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Final stage: ShuffleMapStage 47 (collect at ClusteringSummary.scala:49)\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[138] at collect at ClusteringSummary.scala:49), which has no missing parents\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 67.5 KiB, free 364.2 MiB)\n",
      "22/11/29 14:14:52 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 364.2 MiB)\n",
      "22/11/29 14:14:52 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.17.0.1:38511 (size: 30.1 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:14:52 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[138] at collect at ClusteringSummary.scala:49) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:52 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:52 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 44) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:52 INFO Executor: Running task 0.0 in stage 47.0 (TID 44)\n",
      "22/11/29 14:14:52 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:14:53 INFO Executor: Finished task 0.0 in stage 47.0 (TID 44). 2962 bytes result sent to driver\n",
      "22/11/29 14:14:53 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 44) in 253 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:53 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:53 INFO DAGScheduler: ShuffleMapStage 47 (collect at ClusteringSummary.scala:49) finished in 0.275 s\n",
      "22/11/29 14:14:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:14:53 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:14:53 INFO DAGScheduler: waiting: Set()\n",
      "22/11/29 14:14:53 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:14:53 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "22/11/29 14:14:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n",
      "22/11/29 14:14:53 INFO SparkContext: Starting job: collect at ClusteringSummary.scala:49\n",
      "22/11/29 14:14:53 INFO DAGScheduler: Got job 36 (collect at ClusteringSummary.scala:49) with 1 output partitions\n",
      "22/11/29 14:14:53 INFO DAGScheduler: Final stage: ResultStage 49 (collect at ClusteringSummary.scala:49)\n",
      "22/11/29 14:14:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\n",
      "22/11/29 14:14:53 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:14:53 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[141] at collect at ClusteringSummary.scala:49), which has no missing parents\n",
      "22/11/29 14:14:53 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 58.9 KiB, free 364.1 MiB)\n",
      "22/11/29 14:14:53 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 26.9 KiB, free 364.1 MiB)\n",
      "22/11/29 14:14:53 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.17.0.1:38511 (size: 26.9 KiB, free: 366.0 MiB)\n",
      "22/11/29 14:14:53 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:14:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[141] at collect at ClusteringSummary.scala:49) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:14:53 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:14:53 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 45) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:14:53 INFO Executor: Running task 0.0 in stage 49.0 (TID 45)\n",
      "22/11/29 14:14:53 INFO ShuffleBlockFetcherIterator: Getting 1 (324.0 B) non-empty blocks including 1 (324.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:14:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "22/11/29 14:14:53 INFO Executor: Finished task 0.0 in stage 49.0 (TID 45). 4081 bytes result sent to driver\n",
      "22/11/29 14:14:53 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 45) in 30 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:14:53 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:14:53 INFO DAGScheduler: ResultStage 49 (collect at ClusteringSummary.scala:49) finished in 0.048 s\n",
      "22/11/29 14:14:53 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:14:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished\n",
      "22/11/29 14:14:53 INFO DAGScheduler: Job 36 finished: collect at ClusteringSummary.scala:49, took 0.055200 s\n",
      "22/11/29 14:14:53 INFO Instrumentation: [42aef167] {\"clusterSizes\":\"[1023,553,1658,1782,2478]\"}\n",
      "22/11/29 14:14:53 INFO Instrumentation: [42aef167] training finished\n"
     ]
    }
   ],
   "source": [
    "modelTrain = clusterPipe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "838ab7e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:18:30 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:18:30 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:18:30 INFO FileSourceStrategy: Output Data Schema: struct<ID: string, Delivery_person_ID: string, Type_of_Vehicle: string, DeliveryPersonAge: double, DeliveryPersonRatings: double ... 15 more fields>\n",
      "22/11/29 14:18:30 INFO CodeGenerator: Code generated in 37.578967 ms\n",
      "22/11/29 14:18:30 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 350.3 KiB, free 366.0 MiB)\n",
      "22/11/29 14:18:30 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 365.9 MiB)\n",
      "22/11/29 14:18:30 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.3 MiB)\n",
      "22/11/29 14:18:30 INFO SparkContext: Created broadcast 85 from showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 14:18:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:18:30 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 14:18:30 INFO DAGScheduler: Got job 38 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 14:18:30 INFO DAGScheduler: Final stage: ResultStage 51 (showString at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 14:18:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:18:30 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:18:30 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[149] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 14:18:30 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 57.4 KiB, free 365.9 MiB)\n",
      "22/11/29 14:18:30 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 24.9 KiB, free 365.8 MiB)\n",
      "22/11/29 14:18:30 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.17.0.1:38511 (size: 24.9 KiB, free: 366.2 MiB)\n",
      "22/11/29 14:18:30 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:18:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[149] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:18:30 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:18:30 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 47) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:18:30 INFO Executor: Running task 0.0 in stage 51.0 (TID 47)\n",
      "22/11/29 14:18:30 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:18:30 INFO Executor: Finished task 0.0 in stage 51.0 (TID 47). 2161 bytes result sent to driver\n",
      "22/11/29 14:18:30 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 47) in 151 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:18:30 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:18:30 INFO DAGScheduler: ResultStage 51 (showString at NativeMethodAccessorImpl.java:0) finished in 0.164 s\n",
      "22/11/29 14:18:30 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:18:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n",
      "22/11/29 14:18:30 INFO DAGScheduler: Job 38 finished: showString at NativeMethodAccessorImpl.java:0, took 0.167184 s\n",
      "22/11/29 14:18:30 INFO CodeGenerator: Code generated in 12.845008 ms\n",
      "+----------+--------------------+\n",
      "|prediction|            features|\n",
      "+----------+--------------------+\n",
      "|         2|[1.0,0.0,27.02192...|\n",
      "|         2|[1.0,3.0,23.39487...|\n",
      "+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelTrain.transform(test).select(\"prediction\",\"features\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39cd1ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:25:52 INFO Instrumentation: [9bf526c7] Stage class: KMeans\n",
      "22/11/29 14:25:52 INFO Instrumentation: [9bf526c7] Stage uid: KMeans_4ab97b2a85d4\n",
      "22/11/29 14:25:52 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:25:52 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:25:52 INFO FileSourceStrategy: Output Data Schema: struct<ID: string, Delivery_person_ID: string, Type_of_Vehicle: string, DeliveryPersonAge: double, DeliveryPersonRatings: double ... 15 more fields>\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 350.3 KiB, free 365.5 MiB)\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 365.5 MiB)\n",
      "22/11/29 14:25:52 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.2 MiB)\n",
      "22/11/29 14:25:52 INFO SparkContext: Created broadcast 87 from rdd at Instrumentation.scala:62\n",
      "22/11/29 14:25:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:25:52 INFO Instrumentation: [9bf526c7] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n",
      "22/11/29 14:25:52 INFO Instrumentation: [9bf526c7] {\"featuresCol\":\"features\",\"k\":5}\n",
      "22/11/29 14:25:52 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:25:52 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:25:52 INFO FileSourceStrategy: Output Data Schema: struct<ID: string, Delivery_person_ID: string, Type_of_Vehicle: string, DeliveryPersonAge: double, DeliveryPersonRatings: double ... 15 more fields>\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 350.3 KiB, free 365.1 MiB)\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 365.1 MiB)\n",
      "22/11/29 14:25:52 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.2 MiB)\n",
      "22/11/29 14:25:52 INFO SparkContext: Created broadcast 88 from rdd at KMeans.scala:350\n",
      "22/11/29 14:25:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:25:52 INFO SparkContext: Starting job: takeSample at KMeans.scala:384\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Got job 39 (takeSample at KMeans.scala:384) with 1 output partitions\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Final stage: ResultStage 52 (takeSample at KMeans.scala:384)\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[165] at map at KMeans.scala:223), which has no missing parents\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 53.1 KiB, free 365.0 MiB)\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 365.0 MiB)\n",
      "22/11/29 14:25:52 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.17.0.1:38511 (size: 22.7 KiB, free: 366.2 MiB)\n",
      "22/11/29 14:25:52 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[165] at map at KMeans.scala:223) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:52 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:52 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 48) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5289 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:52 INFO Executor: Running task 0.0 in stage 52.0 (TID 48)\n",
      "22/11/29 14:25:52 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:25:52 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:25:52 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.17.0.1:38511 in memory (size: 24.9 KiB, free: 366.2 MiB)\n",
      "22/11/29 14:25:52 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.17.0.1:38511 in memory (size: 34.1 KiB, free: 366.2 MiB)\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block rdd_165_0 stored as values in memory (estimated size 838.7 KiB, free 364.7 MiB)\n",
      "22/11/29 14:25:52 INFO BlockManagerInfo: Added rdd_165_0 in memory on 172.17.0.1:38511 (size: 838.7 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:25:52 INFO Executor: Finished task 0.0 in stage 52.0 (TID 48). 1892 bytes result sent to driver\n",
      "22/11/29 14:25:52 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 48) in 424 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:52 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:52 INFO DAGScheduler: ResultStage 52 (takeSample at KMeans.scala:384) finished in 0.439 s\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Job 39 finished: takeSample at KMeans.scala:384, took 0.442473 s\n",
      "22/11/29 14:25:52 INFO SparkContext: Starting job: takeSample at KMeans.scala:384\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Got job 40 (takeSample at KMeans.scala:384) with 1 output partitions\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Final stage: ResultStage 53 (takeSample at KMeans.scala:384)\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Submitting ResultStage 53 (PartitionwiseSampledRDD[167] at takeSample at KMeans.scala:384), which has no missing parents\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 53.8 KiB, free 364.6 MiB)\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 364.6 MiB)\n",
      "22/11/29 14:25:52 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.17.0.1:38511 (size: 23.1 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:25:52 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (PartitionwiseSampledRDD[167] at takeSample at KMeans.scala:384) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:52 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:52 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 49) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:52 INFO Executor: Running task 0.0 in stage 53.0 (TID 49)\n",
      "22/11/29 14:25:52 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:52 INFO Executor: Finished task 0.0 in stage 53.0 (TID 49). 3820 bytes result sent to driver\n",
      "22/11/29 14:25:52 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 49) in 14 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:52 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:52 INFO DAGScheduler: ResultStage 53 (takeSample at KMeans.scala:384) finished in 0.022 s\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Job 40 finished: takeSample at KMeans.scala:384, took 0.025354 s\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 160.0 B, free 364.6 MiB)\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 316.0 B, free 364.6 MiB)\n",
      "22/11/29 14:25:52 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.17.0.1:38511 (size: 316.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:25:52 INFO SparkContext: Created broadcast 91 from broadcast at KMeans.scala:398\n",
      "22/11/29 14:25:52 INFO SparkContext: Starting job: sum at KMeans.scala:404\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Got job 41 (sum at KMeans.scala:404) with 1 output partitions\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Final stage: ResultStage 54 (sum at KMeans.scala:404)\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[169] at map at KMeans.scala:401), which has no missing parents\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 54.4 KiB, free 364.5 MiB)\n",
      "22/11/29 14:25:52 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 23.2 KiB, free 364.5 MiB)\n",
      "22/11/29 14:25:52 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.17.0.1:38511 (size: 23.2 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:25:52 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[169] at map at KMeans.scala:401) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:52 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:52 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 50) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5321 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:52 INFO Executor: Running task 0.0 in stage 54.0 (TID 50)\n",
      "22/11/29 14:25:52 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block rdd_169_0 stored as values in memory (estimated size 58.6 KiB, free 364.4 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added rdd_169_0 in memory on 172.17.0.1:38511 (size: 58.6 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 54.0 (TID 50). 1808 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 50) in 27 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ResultStage 54 (sum at KMeans.scala:404) finished in 0.037 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 41 finished: sum at KMeans.scala:404, took 0.039696 s\n",
      "22/11/29 14:25:53 INFO MapPartitionsRDD: Removing RDD 166 from persistence list\n",
      "22/11/29 14:25:53 INFO BlockManager: Removing RDD 166\n",
      "22/11/29 14:25:53 INFO SparkContext: Starting job: collect at KMeans.scala:409\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Got job 42 (collect at KMeans.scala:409) with 1 output partitions\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Final stage: ResultStage 55 (collect at KMeans.scala:409)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[171] at mapPartitionsWithIndex at KMeans.scala:409), which has no missing parents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 54.8 KiB, free 364.4 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 23.3 KiB, free 364.4 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.17.0.1:38511 (size: 23.3 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[171] at mapPartitionsWithIndex at KMeans.scala:409) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 51) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5353 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 55.0 (TID 51)\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_169_0 locally\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 55.0 (TID 51). 2869 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 51) in 16 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ResultStage 55 (collect at KMeans.scala:409) finished in 0.026 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 42 finished: collect at KMeans.scala:409, took 0.028125 s\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 1200.0 B, free 364.4 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 597.0 B, free 364.4 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.17.0.1:38511 (size: 597.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 94 from broadcast at KMeans.scala:398\n",
      "22/11/29 14:25:53 INFO SparkContext: Starting job: sum at KMeans.scala:404\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Got job 43 (sum at KMeans.scala:404) with 1 output partitions\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Final stage: ResultStage 56 (sum at KMeans.scala:404)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[173] at map at KMeans.scala:401), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 54.8 KiB, free 364.3 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 23.3 KiB, free 364.3 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.17.0.1:38511 (size: 23.3 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[173] at map at KMeans.scala:401) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 52) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5353 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 56.0 (TID 52)\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_169_0 locally\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block rdd_173_0 stored as values in memory (estimated size 58.6 KiB, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added rdd_173_0 in memory on 172.17.0.1:38511 (size: 58.6 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 56.0 (TID 52). 1808 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 52) in 25 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ResultStage 56 (sum at KMeans.scala:404) finished in 0.046 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 43 finished: sum at KMeans.scala:404, took 0.049109 s\n",
      "22/11/29 14:25:53 INFO MapPartitionsRDD: Removing RDD 169 from persistence list\n",
      "22/11/29 14:25:53 INFO BlockManager: Removing RDD 169\n",
      "22/11/29 14:25:53 INFO SparkContext: Starting job: collect at KMeans.scala:409\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Got job 44 (collect at KMeans.scala:409) with 1 output partitions\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Final stage: ResultStage 57 (collect at KMeans.scala:409)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[175] at mapPartitionsWithIndex at KMeans.scala:409), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 55.2 KiB, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 23.4 KiB, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.17.0.1:38511 (size: 23.4 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[175] at mapPartitionsWithIndex at KMeans.scala:409) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 53) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5385 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 57.0 (TID 53)\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_173_0 locally\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 57.0 (TID 53). 3474 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 53) in 10 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ResultStage 57 (collect at KMeans.scala:409) finished in 0.020 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 44 finished: collect at KMeans.scala:409, took 0.023966 s\n",
      "22/11/29 14:25:53 INFO MapPartitionsRDD: Removing RDD 173 from persistence list\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(91) (from destroy at KMeans.scala:419)\n",
      "22/11/29 14:25:53 INFO BlockManager: Removing RDD 173\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(94) (from destroy at KMeans.scala:419)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 3.2 KiB, free 364.3 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.17.0.1:38511 in memory (size: 316.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 1574.0 B, free 364.3 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.17.0.1:38511 (size: 1574.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.17.0.1:38511 in memory (size: 597.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 97 from broadcast at KMeans.scala:429\n",
      "22/11/29 14:25:53 INFO SparkContext: Starting job: countByValue at KMeans.scala:432\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Registering RDD 178 (countByValue at KMeans.scala:432) as input to shuffle 13\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Got job 45 (countByValue at KMeans.scala:432) with 1 output partitions\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Final stage: ResultStage 59 (countByValue at KMeans.scala:432)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[178] at countByValue at KMeans.scala:432), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 55.7 KiB, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.17.0.1:38511 (size: 23.9 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[178] at countByValue at KMeans.scala:432) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 54) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 58.0 (TID 54)\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_165_0 locally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 58.0 (TID 54). 2090 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 54) in 108 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ShuffleMapStage 58 (countByValue at KMeans.scala:432) finished in 0.117 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:25:53 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: waiting: Set(ResultStage 59)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ResultStage 59 (ShuffledRDD[179] at countByValue at KMeans.scala:432), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 5.2 KiB, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.17.0.1:38511 (size: 3.0 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (ShuffledRDD[179] at countByValue at KMeans.scala:432) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 55) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 59.0 (TID 55)\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 59.0 (TID 55). 2279 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 55) in 68 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ResultStage 59 (countByValue at KMeans.scala:432) finished in 0.078 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 45 finished: countByValue at KMeans.scala:432, took 0.200674 s\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(97) (from destroy at KMeans.scala:434)\n",
      "22/11/29 14:25:53 INFO LocalKMeans: Local KMeans++ converged in 3 iterations.\n",
      "22/11/29 14:25:53 INFO KMeans: Initialization with k-means|| took 0.962 seconds.\n",
      "22/11/29 14:25:53 INFO Instrumentation: [9bf526c7] {\"numFeatures\":6}\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 624.0 B, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 578.0 B, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.17.0.1:38511 (size: 578.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 100 from broadcast at KMeans.scala:279\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 176.0 B, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.17.0.1:38511 in memory (size: 1574.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.2 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.17.0.1:38511 (size: 250.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 101 from broadcast at KMeans.scala:289\n",
      "22/11/29 14:25:53 INFO SparkContext: Starting job: collectAsMap at KMeans.scala:315\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Registering RDD 180 (mapPartitions at KMeans.scala:294) as input to shuffle 14\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Got job 46 (collectAsMap at KMeans.scala:315) with 1 output partitions\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Final stage: ResultStage 61 (collectAsMap at KMeans.scala:315)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 60)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[180] at mapPartitions at KMeans.scala:294), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 55.0 KiB, free 364.1 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 364.1 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.17.0.1:38511 (size: 23.7 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[180] at mapPartitions at KMeans.scala:294) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 56) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 60.0 (TID 56)\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 60.0 (TID 56). 2203 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 56) in 20 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ShuffleMapStage 60 (mapPartitions at KMeans.scala:294) finished in 0.028 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:25:53 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: waiting: Set(ResultStage 61)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ResultStage 61 (ShuffledRDD[181] at reduceByKey at KMeans.scala:315), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 4.8 KiB, free 364.1 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 364.1 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.17.0.1:38511 (size: 2.8 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (ShuffledRDD[181] at reduceByKey at KMeans.scala:315) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 57) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 61.0 (TID 57)\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 61.0 (TID 57). 2018 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 57) in 12 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ResultStage 61 (collectAsMap at KMeans.scala:315) finished in 0.017 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 46 finished: collectAsMap at KMeans.scala:315, took 0.051461 s\n",
      "22/11/29 14:25:53 INFO Instrumentation: [9bf526c7] {\"numExamples\":7494}\n",
      "22/11/29 14:25:53 INFO Instrumentation: [9bf526c7] {\"sumOfWeights\":7494.0}\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(100) (from destroy at KMeans.scala:325)\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(101) (from destroy at KMeans.scala:326)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 172.17.0.1:38511 in memory (size: 578.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.17.0.1:38511 in memory (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO Instrumentation: [9bf526c7] {\"Cost@iter=0\":\"201545.99019035348\"}\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 624.0 B, free 364.1 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 575.0 B, free 364.1 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.17.0.1:38511 (size: 575.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 104 from broadcast at KMeans.scala:279\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 176.0 B, free 364.1 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.1 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.17.0.1:38511 (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 105 from broadcast at KMeans.scala:289\n",
      "22/11/29 14:25:53 INFO SparkContext: Starting job: collectAsMap at KMeans.scala:315\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Registering RDD 182 (mapPartitions at KMeans.scala:294) as input to shuffle 15\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Got job 47 (collectAsMap at KMeans.scala:315) with 1 output partitions\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Final stage: ResultStage 63 (collectAsMap at KMeans.scala:315)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[182] at mapPartitions at KMeans.scala:294), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 55.0 KiB, free 364.1 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 364.0 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.17.0.1:38511 (size: 23.7 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[182] at mapPartitions at KMeans.scala:294) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 58) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 62.0 (TID 58)\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 62.0 (TID 58). 2203 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 58) in 19 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ShuffleMapStage 62 (mapPartitions at KMeans.scala:294) finished in 0.026 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:25:53 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: waiting: Set(ResultStage 63)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ResultStage 63 (ShuffledRDD[183] at reduceByKey at KMeans.scala:315), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 4.8 KiB, free 364.0 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 364.0 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.17.0.1:38511 (size: 2.8 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (ShuffledRDD[183] at reduceByKey at KMeans.scala:315) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 59) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 63.0 (TID 59)\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 63.0 (TID 59). 2018 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 59) in 10 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ResultStage 63 (collectAsMap at KMeans.scala:315) finished in 0.017 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 47 finished: collectAsMap at KMeans.scala:315, took 0.048063 s\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(104) (from destroy at KMeans.scala:325)\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(105) (from destroy at KMeans.scala:326)\n",
      "22/11/29 14:25:53 INFO Instrumentation: [9bf526c7] {\"Cost@iter=1\":\"189368.06592439843\"}\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 624.0 B, free 364.0 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.17.0.1:38511 in memory (size: 575.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 568.0 B, free 364.0 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.17.0.1:38511 (size: 568.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 108 from broadcast at KMeans.scala:279\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 172.17.0.1:38511 in memory (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 176.0 B, free 364.0 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 250.0 B, free 364.0 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.17.0.1:38511 (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 109 from broadcast at KMeans.scala:289\n",
      "22/11/29 14:25:53 INFO SparkContext: Starting job: collectAsMap at KMeans.scala:315\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Registering RDD 184 (mapPartitions at KMeans.scala:294) as input to shuffle 16\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Got job 48 (collectAsMap at KMeans.scala:315) with 1 output partitions\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Final stage: ResultStage 65 (collectAsMap at KMeans.scala:315)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[184] at mapPartitions at KMeans.scala:294), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 55.0 KiB, free 364.0 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.17.0.1:38511 (size: 23.7 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[184] at mapPartitions at KMeans.scala:294) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 60) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 64.0 (TID 60)\n",
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 64.0 (TID 60). 2203 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 60) in 16 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ShuffleMapStage 64 (mapPartitions at KMeans.scala:294) finished in 0.026 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:25:53 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: waiting: Set(ResultStage 65)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ResultStage 65 (ShuffledRDD[185] at reduceByKey at KMeans.scala:315), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 4.8 KiB, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.17.0.1:38511 (size: 2.8 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (ShuffledRDD[185] at reduceByKey at KMeans.scala:315) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 61) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 65.0 (TID 61)\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 65.0 (TID 61). 2018 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 61) in 7 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ResultStage 65 (collectAsMap at KMeans.scala:315) finished in 0.014 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 48 finished: collectAsMap at KMeans.scala:315, took 0.046982 s\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(108) (from destroy at KMeans.scala:325)\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(109) (from destroy at KMeans.scala:326)\n",
      "22/11/29 14:25:53 INFO Instrumentation: [9bf526c7] {\"Cost@iter=2\":\"189178.65374037324\"}\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 624.0 B, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.17.0.1:38511 in memory (size: 568.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 568.0 B, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.17.0.1:38511 (size: 568.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 112 from broadcast at KMeans.scala:279\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 176.0 B, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 250.0 B, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.17.0.1:38511 (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 113 from broadcast at KMeans.scala:289\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.17.0.1:38511 in memory (size: 250.0 B, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Starting job: collectAsMap at KMeans.scala:315\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Registering RDD 186 (mapPartitions at KMeans.scala:294) as input to shuffle 17\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Got job 49 (collectAsMap at KMeans.scala:315) with 1 output partitions\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Final stage: ResultStage 67 (collectAsMap at KMeans.scala:315)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[186] at mapPartitions at KMeans.scala:294), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 55.0 KiB, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.17.0.1:38511 (size: 23.7 KiB, free: 365.2 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[186] at mapPartitions at KMeans.scala:294) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 62) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5278 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 66.0 (TID 62)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:25:53 INFO BlockManager: Found block rdd_165_0 locally\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 66.0 (TID 62). 2203 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 62) in 29 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ShuffleMapStage 66 (mapPartitions at KMeans.scala:294) finished in 0.051 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:25:53 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: waiting: Set(ResultStage 67)\n",
      "22/11/29 14:25:53 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting ResultStage 67 (ShuffledRDD[187] at reduceByKey at KMeans.scala:315), which has no missing parents\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 4.8 KiB, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 363.9 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.17.0.1:38511 (size: 2.8 KiB, free: 365.1 MiB)\n",
      "22/11/29 14:25:53 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (ShuffledRDD[187] at reduceByKey at KMeans.scala:315) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 63) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:53 INFO Executor: Running task 0.0 in stage 67.0 (TID 63)\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Getting 1 (652.0 B) non-empty blocks including 1 (652.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:25:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "22/11/29 14:25:53 INFO Executor: Finished task 0.0 in stage 67.0 (TID 63). 2018 bytes result sent to driver\n",
      "22/11/29 14:25:53 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 63) in 14 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:53 INFO DAGScheduler: ResultStage 67 (collectAsMap at KMeans.scala:315) finished in 0.031 s\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished\n",
      "22/11/29 14:25:53 INFO DAGScheduler: Job 49 finished: collectAsMap at KMeans.scala:315, took 0.094075 s\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(112) (from destroy at KMeans.scala:325)\n",
      "22/11/29 14:25:53 INFO TorrentBroadcast: Destroying Broadcast(113) (from destroy at KMeans.scala:326)\n",
      "22/11/29 14:25:53 INFO Instrumentation: [9bf526c7] {\"Cost@iter=3\":\"189166.82917531478\"}\n",
      "22/11/29 14:25:53 INFO KMeans: Iterations took 0.386 seconds.\n",
      "22/11/29 14:25:53 INFO KMeans: KMeans converged in 4 iterations.\n",
      "22/11/29 14:25:53 INFO KMeans: The cost is 189166.82917531478.\n",
      "22/11/29 14:25:53 INFO MapPartitionsRDD: Removing RDD 165 from persistence list\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 172.17.0.1:38511 in memory (size: 568.0 B, free: 366.0 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.17.0.1:38511 in memory (size: 250.0 B, free: 366.0 MiB)\n",
      "22/11/29 14:25:53 INFO BlockManager: Removing RDD 165\n",
      "22/11/29 14:25:54 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:25:54 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:25:54 INFO FileSourceStrategy: Output Data Schema: struct<ID: string, Delivery_person_ID: string, Type_of_Vehicle: string, DeliveryPersonAge: double, DeliveryPersonRatings: double ... 15 more fields>\n",
      "22/11/29 14:25:54 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 350.3 KiB, free 364.3 MiB)\n",
      "22/11/29 14:25:54 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 364.3 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:25:54 INFO SparkContext: Created broadcast 116 from collect at ClusteringSummary.scala:49\n",
      "22/11/29 14:25:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Registering RDD 191 (collect at ClusteringSummary.scala:49) as input to shuffle 18\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Got map stage job 50 (collect at ClusteringSummary.scala:49) with 1 output partitions\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Final stage: ShuffleMapStage 68 (collect at ClusteringSummary.scala:49)\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[191] at collect at ClusteringSummary.scala:49), which has no missing parents\n",
      "22/11/29 14:25:54 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 67.5 KiB, free 364.2 MiB)\n",
      "22/11/29 14:25:54 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 364.2 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.17.0.1:38511 (size: 30.0 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:25:54 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[191] at collect at ClusteringSummary.scala:49) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:54 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:54 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 64) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:54 INFO Executor: Running task 0.0 in stage 68.0 (TID 64)\n",
      "22/11/29 14:25:54 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.17.0.1:38511 in memory (size: 23.2 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 172.17.0.1:38511 in memory (size: 2.8 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.17.0.1:38511 in memory (size: 23.7 KiB, free: 366.0 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 172.17.0.1:38511 in memory (size: 2.8 KiB, free: 366.0 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 172.17.0.1:38511 in memory (size: 23.1 KiB, free: 366.0 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManager: Removing RDD 169\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 172.17.0.1:38511 in memory (size: 2.8 KiB, free: 366.0 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.17.0.1:38511 in memory (size: 23.9 KiB, free: 366.0 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.17.0.1:38511 in memory (size: 23.3 KiB, free: 366.0 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.17.0.1:38511 in memory (size: 23.3 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManager: Removing RDD 173\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.17.0.1:38511 in memory (size: 23.4 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.17.0.1:38511 in memory (size: 3.0 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.17.0.1:38511 in memory (size: 2.8 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.17.0.1:38511 in memory (size: 23.7 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.17.0.1:38511 in memory (size: 23.7 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.17.0.1:38511 in memory (size: 23.7 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:25:54 INFO Executor: Finished task 0.0 in stage 68.0 (TID 64). 3005 bytes result sent to driver\n",
      "22/11/29 14:25:54 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 64) in 280 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:54 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:54 INFO DAGScheduler: ShuffleMapStage 68 (collect at ClusteringSummary.scala:49) finished in 0.308 s\n",
      "22/11/29 14:25:54 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:25:54 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:25:54 INFO DAGScheduler: waiting: Set()\n",
      "22/11/29 14:25:54 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:25:54 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576\n",
      "22/11/29 14:25:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:25:54 INFO SparkContext: Starting job: collect at ClusteringSummary.scala:49\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Got job 51 (collect at ClusteringSummary.scala:49) with 1 output partitions\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Final stage: ResultStage 70 (collect at ClusteringSummary.scala:49)\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 69)\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[194] at collect at ClusteringSummary.scala:49), which has no missing parents\n",
      "22/11/29 14:25:54 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 58.9 KiB, free 364.9 MiB)\n",
      "22/11/29 14:25:54 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 27.0 KiB, free 364.9 MiB)\n",
      "22/11/29 14:25:54 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.17.0.1:38511 (size: 27.0 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:25:54 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[194] at collect at ClusteringSummary.scala:49) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:25:54 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:25:54 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 65) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:25:54 INFO Executor: Running task 0.0 in stage 70.0 (TID 65)\n",
      "22/11/29 14:25:54 INFO ShuffleBlockFetcherIterator: Getting 1 (324.0 B) non-empty blocks including 1 (324.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:25:54 INFO Executor: Finished task 0.0 in stage 70.0 (TID 65). 4081 bytes result sent to driver\n",
      "22/11/29 14:25:54 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 65) in 16 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:25:54 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:25:54 INFO DAGScheduler: ResultStage 70 (collect at ClusteringSummary.scala:49) finished in 0.031 s\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:25:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished\n",
      "22/11/29 14:25:54 INFO DAGScheduler: Job 51 finished: collect at ClusteringSummary.scala:49, took 0.037684 s\n",
      "22/11/29 14:25:54 INFO Instrumentation: [9bf526c7] {\"clusterSizes\":\"[1023,553,1658,1782,2478]\"}\n",
      "22/11/29 14:25:54 INFO Instrumentation: [9bf526c7] training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.48093842,  2.4115347 , 15.239162  , 79.40888819, 79.34755876,\n",
       "        15.17783257]),\n",
       " array([1.52622061, 2.34538879, 0.06019892, 0.06019892, 0.        ,\n",
       "        0.        ]),\n",
       " array([ 1.4517491 ,  2.49939686, 25.98590155, 79.93074181, 79.86386605,\n",
       "        25.91902579]),\n",
       " array([ 1.47923681,  2.43995511, 12.34483727, 76.93604159, 76.87223126,\n",
       "        11.68501101]),\n",
       " array([ 1.47013721,  2.46004843, 20.6528718 , 73.90865709, 73.84663126,\n",
       "        20.59084598])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(featuresCol=\"features\",k=5)\n",
    "kmeans.fit(clusterAssy.transform(train)).clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf00201b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:30:41 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:30:41 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:30:41 INFO FileSourceStrategy: Output Data Schema: struct<ID: string, Delivery_person_ID: string, Type_of_Vehicle: string, DeliveryPersonAge: double, DeliveryPersonRatings: double ... 15 more fields>\n",
      "22/11/29 14:30:41 INFO CodeGenerator: Code generated in 24.595884 ms\n",
      "22/11/29 14:30:41 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 350.3 KiB, free 363.5 MiB)\n",
      "22/11/29 14:30:41 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 363.4 MiB)\n",
      "22/11/29 14:30:41 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.0 MiB)\n",
      "22/11/29 14:30:41 INFO SparkContext: Created broadcast 151 from showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 14:30:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:30:41 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 14:30:41 INFO DAGScheduler: Got job 65 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 14:30:41 INFO DAGScheduler: Final stage: ResultStage 90 (showString at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 14:30:41 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:30:41 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:30:41 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[243] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 14:30:41 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 37.5 KiB, free 363.4 MiB)\n",
      "22/11/29 14:30:41 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 363.4 MiB)\n",
      "22/11/29 14:30:41 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 172.17.0.1:38511 (size: 15.9 KiB, free: 366.0 MiB)\n",
      "22/11/29 14:30:41 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:30:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[243] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:30:41 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:30:41 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 84) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:30:41 INFO Executor: Running task 0.0 in stage 90.0 (TID 84)\n",
      "22/11/29 14:30:41 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:30:41 INFO Executor: Finished task 0.0 in stage 90.0 (TID 84). 2484 bytes result sent to driver\n",
      "22/11/29 14:30:41 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 84) in 133 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:30:41 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:30:41 INFO DAGScheduler: ResultStage 90 (showString at NativeMethodAccessorImpl.java:0) finished in 0.140 s\n",
      "22/11/29 14:30:41 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:30:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished\n",
      "22/11/29 14:30:41 INFO DAGScheduler: Job 65 finished: showString at NativeMethodAccessorImpl.java:0, took 0.143896 s\n",
      "22/11/29 14:30:41 INFO CodeGenerator: Code generated in 28.6102 ms\n",
      "+------+------------------+---------------+-----------------+---------------------+-------------+----------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+------------------------+-----------------+-----------------------+--------------+\n",
      "|    ID|Delivery_person_ID|Type_of_Vehicle|DeliveryPersonAge|DeliveryPersonRatings|TypeOfVehicle|DeliveryPersonID|Restaurant_latitude|Restaurant_longitude|Delivery_location_latitude|Delivery_location_longitude|Order_Date|Weather_idx|Road_traffic_density_idx|Type_of_order_idx|multiple_deliveries_idx|IntervalPickup|\n",
      "+------+------------------+---------------+-----------------+---------------------+-------------+----------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+------------------------+-----------------+-----------------------+--------------+\n",
      "|0x1008|    PUNERES06DEL02|     motorcycle|             29.0|                  4.9|          0.0|           592.0|          18.546258|           73.904337|                 18.676258|                  74.034337|20-03-2022|        2.0|                     0.0|              2.0|                    0.0|           300|\n",
      "|0x100c|     MYSRES09DEL02|     motorcycle|             33.0|                  4.7|          0.0|           539.0|          12.323194|           76.630583|                 12.373194|                  76.680583|24-03-2022|        3.0|                     2.0|              0.0|                    0.0|           600|\n",
      "+------+------------------+---------------+-----------------+---------------------+-------------+----------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+------------------------+-----------------+-----------------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf915472",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler =clusterAssy = VectorAssembler(inputCols=[\"Type_of_order_idx\",\"Weather_idx\",\n",
    "                                        \"Delivery_location_latitude\",\"Delivery_location_longitude\",\n",
    "                                        \"Restaurant_longitude\",\"Restaurant_latitude\"],\n",
    "                             outputCol=\"features\")\n",
    "\n",
    "log_reg = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "pipeline = Pipeline(stages = [assembler, log_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64d217ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomClass = RandomForestClassifier()\n",
    "ranPipeline = Pipeline(stages=[assembler,randomClass])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "accbe878",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_c, test_c) = clusteringData.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5482e808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:33:16 INFO Instrumentation: [38942545] Stage class: LogisticRegression\n",
      "22/11/29 14:33:16 INFO Instrumentation: [38942545] Stage uid: LogisticRegression_407bb945bcc2\n",
      "22/11/29 14:33:16 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:33:16 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:33:16 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:33:16 INFO CodeGenerator: Code generated in 28.340644 ms\n",
      "22/11/29 14:33:16 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 350.3 KiB, free 362.8 MiB)\n",
      "22/11/29 14:33:16 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 362.8 MiB)\n",
      "22/11/29 14:33:16 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:33:16 INFO SparkContext: Created broadcast 186 from rdd at Instrumentation.scala:62\n",
      "22/11/29 14:33:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:33:17 INFO Instrumentation: [38942545] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n",
      "22/11/29 14:33:17 INFO Instrumentation: [38942545] {\"labelCol\":\"label\",\"featuresCol\":\"features\",\"maxIter\":10}\n",
      "22/11/29 14:33:17 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:33:17 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:33:17 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:33:17 INFO CodeGenerator: Code generated in 36.148912 ms\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 350.3 KiB, free 362.4 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 362.4 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 187 from rdd at Predictor.scala:81\n",
      "22/11/29 14:33:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:33:17 INFO SparkContext: Starting job: treeAggregate at Summarizer.scala:233\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Got job 80 (treeAggregate at Summarizer.scala:233) with 1 output partitions\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Final stage: ResultStage 105 (treeAggregate at Summarizer.scala:233)\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[299] at treeAggregate at Summarizer.scala:233), which has no missing parents\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 54.4 KiB, free 362.3 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 362.3 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 172.17.0.1:38511 (size: 23.0 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[299] at treeAggregate at Summarizer.scala:233) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 99) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:17 INFO Executor: Running task 0.0 in stage 105.0 (TID 99)\n",
      "22/11/29 14:33:17 INFO CodeGenerator: Code generated in 20.663811 ms\n",
      "22/11/29 14:33:17 INFO CodeGenerator: Code generated in 13.441549 ms\n",
      "22/11/29 14:33:17 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:33:17 INFO Executor: Finished task 0.0 in stage 105.0 (TID 99). 3427 bytes result sent to driver\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 99) in 297 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:17 INFO DAGScheduler: ResultStage 105 (treeAggregate at Summarizer.scala:233) finished in 0.310 s\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 80 finished: treeAggregate at Summarizer.scala:233, took 0.315055 s\n",
      "22/11/29 14:33:17 INFO Instrumentation: [38942545] {\"numClasses\":5}\n",
      "22/11/29 14:33:17 INFO Instrumentation: [38942545] {\"numFeatures\":6}\n",
      "22/11/29 14:33:17 INFO Instrumentation: [38942545] {\"numExamples\":8550}\n",
      "22/11/29 14:33:17 INFO Instrumentation: [38942545] {\"lowestLabelWeight\":\"18.0\"}\n",
      "22/11/29 14:33:17 INFO Instrumentation: [38942545] {\"highestLabelWeight\":\"2928.0\"}\n",
      "22/11/29 14:33:17 INFO Instrumentation: [38942545] {\"sumOfWeights\":8550.0}\n",
      "22/11/29 14:33:17 INFO Instrumentation: [38942545] {\"actualBlockSizeInMB\":\"1.0\"}\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 88.0 B, free 362.3 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 117.0 B, free 362.3 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 172.17.0.1:38511 (size: 117.0 B, free: 365.9 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 189 from broadcast at LogisticRegression.scala:959\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 88.0 B, free 362.3 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 117.0 B, free 362.3 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 172.17.0.1:38511 (size: 117.0 B, free: 365.9 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 190 from broadcast at LogisticRegression.scala:960\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 336.0 B, free 362.3 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 187.0 B, free 362.3 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 172.17.0.1:38511 (size: 187.0 B, free: 365.9 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 191 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:17 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Got job 81 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Final stage: ResultStage 106 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[302] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 56.1 KiB, free 362.2 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 362.2 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[302] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 100) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:17 INFO Executor: Running task 0.0 in stage 106.0 (TID 100)\n",
      "22/11/29 14:33:17 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:33:17 INFO MemoryStore: Block rdd_301_0 stored as values in memory (estimated size 467.7 KiB, free 361.8 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added rdd_301_0 in memory on 172.17.0.1:38511 (size: 467.7 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:17 INFO Executor: Finished task 0.0 in stage 106.0 (TID 100). 3093 bytes result sent to driver\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 100) in 236 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:17 INFO DAGScheduler: ResultStage 106 (treeAggregate at RDDLossFunction.scala:61) finished in 0.248 s\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 81 finished: treeAggregate at RDDLossFunction.scala:61, took 0.251896 s\n",
      "22/11/29 14:33:17 INFO TorrentBroadcast: Destroying Broadcast(191) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 336.0 B, free 361.8 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 172.17.0.1:38511 in memory (size: 187.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.8 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 193 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:17 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Got job 82 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Final stage: ResultStage 107 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[303] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 56.1 KiB, free 361.7 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.7 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[303] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 101) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:17 INFO Executor: Running task 0.0 in stage 107.0 (TID 101)\n",
      "22/11/29 14:33:17 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:17 INFO Executor: Finished task 0.0 in stage 107.0 (TID 101). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 101) in 20 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:17 INFO DAGScheduler: ResultStage 107 (treeAggregate at RDDLossFunction.scala:61) finished in 0.027 s\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 82 finished: treeAggregate at RDDLossFunction.scala:61, took 0.030913 s\n",
      "22/11/29 14:33:17 INFO TorrentBroadcast: Destroying Broadcast(193) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 336.0 B, free 361.7 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.7 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 195 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:17 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Got job 83 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Final stage: ResultStage 108 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[304] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 56.1 KiB, free 361.6 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.6 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[304] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 102) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:17 INFO Executor: Running task 0.0 in stage 108.0 (TID 102)\n",
      "22/11/29 14:33:17 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:17 INFO Executor: Finished task 0.0 in stage 108.0 (TID 102). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 102) in 33 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:17 INFO DAGScheduler: ResultStage 108 (treeAggregate at RDDLossFunction.scala:61) finished in 0.051 s\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 108: Stage finished\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 83 finished: treeAggregate at RDDLossFunction.scala:61, took 0.053728 s\n",
      "22/11/29 14:33:17 INFO TorrentBroadcast: Destroying Broadcast(195) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:17 INFO StrongWolfeLineSearch: Line search t: 5.142601256704394 fval: 1.3158564480626587 rhs: 1.315198811885616 cdd: 6.291382178912749E-4\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 336.0 B, free 361.6 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.6 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 197 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:17 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Got job 84 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Final stage: ResultStage 109 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[305] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 56.1 KiB, free 361.6 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.5 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:33:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[305] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 103) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:17 INFO Executor: Running task 0.0 in stage 109.0 (TID 103)\n",
      "22/11/29 14:33:17 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:17 INFO Executor: Finished task 0.0 in stage 109.0 (TID 103). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:17 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 103) in 34 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:17 INFO DAGScheduler: ResultStage 109 (treeAggregate at RDDLossFunction.scala:61) finished in 0.081 s\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished\n",
      "22/11/29 14:33:17 INFO DAGScheduler: Job 84 finished: treeAggregate at RDDLossFunction.scala:61, took 0.086797 s\n",
      "22/11/29 14:33:17 INFO TorrentBroadcast: Destroying Broadcast(197) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:17 INFO StrongWolfeLineSearch: Line search t: 1.9138071766034583 fval: 1.314837407193772 rhs: 1.3151989339740842 cdd: -1.6321514761076113E-7\n",
      "22/11/29 14:33:17 INFO LBFGS: Step Size: 1.914\n",
      "22/11/29 14:33:17 INFO LBFGS: Val and Grad Norm: 1.31484 (rel: 0.000275) 0.0149454\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 336.0 B, free 361.5 MiB)\n",
      "22/11/29 14:33:17 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.5 MiB)\n",
      "22/11/29 14:33:17 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:17 INFO SparkContext: Created broadcast 199 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:18 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Got job 85 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Final stage: ResultStage 110 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[306] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 56.1 KiB, free 361.5 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.5 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 110 (MapPartitionsRDD[306] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 104) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:18 INFO Executor: Running task 0.0 in stage 110.0 (TID 104)\n",
      "22/11/29 14:33:18 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 172.17.0.1:38511 in memory (size: 23.6 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 172.17.0.1:38511 in memory (size: 23.6 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 172.17.0.1:38511 in memory (size: 23.0 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 172.17.0.1:38511 in memory (size: 23.6 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 172.17.0.1:38511 in memory (size: 23.6 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO Executor: Finished task 0.0 in stage 110.0 (TID 104). 3093 bytes result sent to driver\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 104) in 41 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:18 INFO DAGScheduler: ResultStage 110 (treeAggregate at RDDLossFunction.scala:61) finished in 0.051 s\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 110: Stage finished\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 85 finished: treeAggregate at RDDLossFunction.scala:61, took 0.053424 s\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(199) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO LBFGS: Step Size: 1.000\n",
      "22/11/29 14:33:18 INFO LBFGS: Val and Grad Norm: 1.31463 (rel: 0.000154) 0.00872181\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 336.0 B, free 361.8 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.8 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 201 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:18 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Got job 86 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Final stage: ResultStage 111 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[307] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 56.1 KiB, free 361.8 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.8 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[307] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 105) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:18 INFO Executor: Running task 0.0 in stage 111.0 (TID 105)\n",
      "22/11/29 14:33:18 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:18 INFO Executor: Finished task 0.0 in stage 111.0 (TID 105). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 105) in 16 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:18 INFO DAGScheduler: ResultStage 111 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 86 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025816 s\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(201) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:18 INFO LBFGS: Step Size: 1.000\n",
      "22/11/29 14:33:18 INFO LBFGS: Val and Grad Norm: 1.31443 (rel: 0.000155) 0.00816091\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 336.0 B, free 361.8 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.8 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 203 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:18 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Got job 87 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Final stage: ResultStage 112 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[308] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 56.1 KiB, free 361.7 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.7 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[308] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 106) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:33:18 INFO Executor: Running task 0.0 in stage 112.0 (TID 106)\n",
      "22/11/29 14:33:18 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:18 INFO Executor: Finished task 0.0 in stage 112.0 (TID 106). 3093 bytes result sent to driver\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 106) in 17 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:18 INFO DAGScheduler: ResultStage 112 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 112: Stage finished\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 87 finished: treeAggregate at RDDLossFunction.scala:61, took 0.026092 s\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(203) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO LBFGS: Step Size: 1.000\n",
      "22/11/29 14:33:18 INFO LBFGS: Val and Grad Norm: 1.31416 (rel: 0.000209) 0.0123947\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 336.0 B, free 361.7 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.7 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 205 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:18 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Got job 88 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Final stage: ResultStage 113 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[309] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 56.1 KiB, free 361.6 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.6 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[309] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 107) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:18 INFO Executor: Running task 0.0 in stage 113.0 (TID 107)\n",
      "22/11/29 14:33:18 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:18 INFO Executor: Finished task 0.0 in stage 113.0 (TID 107). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 107) in 15 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:18 INFO DAGScheduler: ResultStage 113 (treeAggregate at RDDLossFunction.scala:61) finished in 0.020 s\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 88 finished: treeAggregate at RDDLossFunction.scala:61, took 0.022406 s\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(205) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO LBFGS: Step Size: 1.000\n",
      "22/11/29 14:33:18 INFO LBFGS: Val and Grad Norm: 1.31346 (rel: 0.000533) 0.0208678\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 336.0 B, free 361.6 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.6 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.4 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 207 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:18 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Got job 89 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Final stage: ResultStage 114 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[310] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 56.1 KiB, free 361.6 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.5 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[310] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 108) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:18 INFO Executor: Running task 0.0 in stage 114.0 (TID 108)\n",
      "22/11/29 14:33:18 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:18 INFO Executor: Finished task 0.0 in stage 114.0 (TID 108). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 108) in 15 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:18 INFO DAGScheduler: ResultStage 114 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 89 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025755 s\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(207) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO LBFGS: Step Size: 1.000\n",
      "22/11/29 14:33:18 INFO LBFGS: Val and Grad Norm: 1.31269 (rel: 0.000582) 0.0334322\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 336.0 B, free 361.5 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.5 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 209 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:18 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Got job 90 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Final stage: ResultStage 115 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[311] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 56.1 KiB, free 361.5 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.5 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[311] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 109) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:18 INFO Executor: Running task 0.0 in stage 115.0 (TID 109)\n",
      "22/11/29 14:33:18 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:18 INFO Executor: Finished task 0.0 in stage 115.0 (TID 109). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 109) in 15 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:18 INFO DAGScheduler: ResultStage 115 (treeAggregate at RDDLossFunction.scala:61) finished in 0.022 s\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 115: Stage finished\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 90 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025272 s\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(209) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:18 INFO LBFGS: Step Size: 1.000\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO LBFGS: Val and Grad Norm: 1.31187 (rel: 0.000630) 0.0217790\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 336.0 B, free 361.5 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.5 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 211 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:18 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Got job 91 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Final stage: ResultStage 116 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[312] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 56.1 KiB, free 361.4 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.4 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[312] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 110) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:18 INFO Executor: Running task 0.0 in stage 116.0 (TID 110)\n",
      "22/11/29 14:33:18 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:18 INFO Executor: Finished task 0.0 in stage 116.0 (TID 110). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 110) in 14 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:18 INFO DAGScheduler: ResultStage 116 (treeAggregate at RDDLossFunction.scala:61) finished in 0.019 s\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 116: Stage finished\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 91 finished: treeAggregate at RDDLossFunction.scala:61, took 0.021126 s\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(211) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:18 INFO LBFGS: Step Size: 1.000\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO LBFGS: Val and Grad Norm: 1.31120 (rel: 0.000509) 0.0112901\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 336.0 B, free 361.4 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.4 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 213 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:18 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Got job 92 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Final stage: ResultStage 117 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[313] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 56.1 KiB, free 361.3 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.3 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[313] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 111) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:18 INFO Executor: Running task 0.0 in stage 117.0 (TID 111)\n",
      "22/11/29 14:33:18 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:18 INFO Executor: Finished task 0.0 in stage 117.0 (TID 111). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 111) in 19 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:18 INFO DAGScheduler: ResultStage 117 (treeAggregate at RDDLossFunction.scala:61) finished in 0.031 s\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 92 finished: treeAggregate at RDDLossFunction.scala:61, took 0.034248 s\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(213) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:18 INFO LBFGS: Step Size: 1.000\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO LBFGS: Val and Grad Norm: 1.31092 (rel: 0.000211) 0.00846360\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 336.0 B, free 361.3 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 418.0 B, free 361.3 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 172.17.0.1:38511 (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 215 from broadcast at RDDLossFunction.scala:57\n",
      "22/11/29 14:33:18 INFO SparkContext: Starting job: treeAggregate at RDDLossFunction.scala:61\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Got job 93 (treeAggregate at RDDLossFunction.scala:61) with 1 output partitions\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Final stage: ResultStage 118 (treeAggregate at RDDLossFunction.scala:61)\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[314] at treeAggregate at RDDLossFunction.scala:61), which has no missing parents\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 56.1 KiB, free 361.2 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 23.6 KiB, free 361.2 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 172.17.0.1:38511 (size: 23.6 KiB, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[314] at treeAggregate at RDDLossFunction.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 112) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:33:18 INFO Executor: Running task 0.0 in stage 118.0 (TID 112)\n",
      "22/11/29 14:33:18 INFO BlockManager: Found block rdd_301_0 locally\n",
      "22/11/29 14:33:18 INFO Executor: Finished task 0.0 in stage 118.0 (TID 112). 3050 bytes result sent to driver\n",
      "22/11/29 14:33:18 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 112) in 15 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:33:18 INFO DAGScheduler: ResultStage 118 (treeAggregate at RDDLossFunction.scala:61) finished in 0.023 s\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:33:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 118: Stage finished\n",
      "22/11/29 14:33:18 INFO DAGScheduler: Job 93 finished: treeAggregate at RDDLossFunction.scala:61, took 0.025767 s\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(215) (from destroy at RDDLossFunction.scala:68)\n",
      "22/11/29 14:33:18 INFO LBFGS: Step Size: 1.000\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 172.17.0.1:38511 in memory (size: 418.0 B, free: 365.3 MiB)\n",
      "22/11/29 14:33:18 INFO LBFGS: Val and Grad Norm: 1.31072 (rel: 0.000154) 0.00858243\n",
      "22/11/29 14:33:18 INFO LBFGS: Converged because max iterations reached\n",
      "22/11/29 14:33:18 INFO MapPartitionsRDD: Removing RDD 301 from persistence list\n",
      "22/11/29 14:33:18 INFO BlockManager: Removing RDD 301\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(189) (from destroy at LogisticRegression.scala:1014)\n",
      "22/11/29 14:33:18 INFO TorrentBroadcast: Destroying Broadcast(190) (from destroy at LogisticRegression.scala:1015)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 172.17.0.1:38511 in memory (size: 117.0 B, free: 365.7 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 172.17.0.1:38511 in memory (size: 117.0 B, free: 365.7 MiB)\n",
      "22/11/29 14:33:18 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:33:18 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:33:18 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:33:18 INFO CodeGenerator: Code generated in 31.63206 ms\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 350.3 KiB, free 361.3 MiB)\n",
      "22/11/29 14:33:18 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 361.3 MiB)\n",
      "22/11/29 14:33:18 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.7 MiB)\n",
      "22/11/29 14:33:18 INFO SparkContext: Created broadcast 217 from rdd at ClassificationSummary.scala:58\n",
      "22/11/29 14:33:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n"
     ]
    }
   ],
   "source": [
    "modelPipe = pipeline.fit(train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1197532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = modelPipe.transform(test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e72a862b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:34:40 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:34:40 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:34:40 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:34:40 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 350.3 KiB, free 361.9 MiB)\n",
      "22/11/29 14:34:40 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 361.9 MiB)\n",
      "22/11/29 14:34:40 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:34:40 INFO SparkContext: Created broadcast 222 from showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 14:34:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:34:40 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 14:34:40 INFO DAGScheduler: Got job 96 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 14:34:40 INFO DAGScheduler: Final stage: ResultStage 121 (showString at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 14:34:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:34:40 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:34:40 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[333] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 14:34:40 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 63.0 KiB, free 361.9 MiB)\n",
      "22/11/29 14:34:40 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 26.9 KiB, free 361.8 MiB)\n",
      "22/11/29 14:34:40 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 172.17.0.1:38511 (size: 26.9 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:34:40 INFO SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[333] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:34:40 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:34:40 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 115) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:34:40 INFO Executor: Running task 0.0 in stage 121.0 (TID 115)\n",
      "22/11/29 14:34:40 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:34:40 INFO Executor: Finished task 0.0 in stage 121.0 (TID 115). 2035 bytes result sent to driver\n",
      "22/11/29 14:34:40 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 115) in 140 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:34:40 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:34:40 INFO DAGScheduler: ResultStage 121 (showString at NativeMethodAccessorImpl.java:0) finished in 0.149 s\n",
      "22/11/29 14:34:40 INFO DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:34:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 121: Stage finished\n",
      "22/11/29 14:34:40 INFO DAGScheduler: Job 96 finished: showString at NativeMethodAccessorImpl.java:0, took 0.151202 s\n",
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"prediction\",\"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc2e507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator,MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "07147541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:39:51 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:39:51 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:39:51 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:39:51 INFO CodeGenerator: Code generated in 26.120088 ms\n",
      "22/11/29 14:39:51 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 350.3 KiB, free 361.5 MiB)\n",
      "22/11/29 14:39:51 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 361.5 MiB)\n",
      "22/11/29 14:39:51 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:39:51 INFO SparkContext: Created broadcast 224 from rdd at MulticlassClassificationEvaluator.scala:203\n",
      "22/11/29 14:39:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:39:51 INFO SparkContext: Starting job: collectAsMap at MulticlassMetrics.scala:61\n",
      "22/11/29 14:39:51 INFO DAGScheduler: Registering RDD 341 (map at MulticlassMetrics.scala:52) as input to shuffle 25\n",
      "22/11/29 14:39:51 INFO DAGScheduler: Got job 97 (collectAsMap at MulticlassMetrics.scala:61) with 1 output partitions\n",
      "22/11/29 14:39:51 INFO DAGScheduler: Final stage: ResultStage 123 (collectAsMap at MulticlassMetrics.scala:61)\n",
      "22/11/29 14:39:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)\n",
      "22/11/29 14:39:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 122)\n",
      "22/11/29 14:39:51 INFO DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[341] at map at MulticlassMetrics.scala:52), which has no missing parents\n",
      "22/11/29 14:39:51 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 67.5 KiB, free 361.4 MiB)\n",
      "22/11/29 14:39:51 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 361.4 MiB)\n",
      "22/11/29 14:39:51 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 172.17.0.1:38511 (size: 29.2 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:39:51 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:39:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[341] at map at MulticlassMetrics.scala:52) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:39:51 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:39:51 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 116) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:39:51 INFO Executor: Running task 0.0 in stage 122.0 (TID 116)\n",
      "22/11/29 14:39:51 INFO CodeGenerator: Code generated in 6.920362 ms\n",
      "22/11/29 14:39:51 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:39:52 INFO Executor: Finished task 0.0 in stage 122.0 (TID 116). 2090 bytes result sent to driver\n",
      "22/11/29 14:39:52 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 116) in 259 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:39:52 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:39:52 INFO DAGScheduler: ShuffleMapStage 122 (map at MulticlassMetrics.scala:52) finished in 0.270 s\n",
      "22/11/29 14:39:52 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:39:52 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:39:52 INFO DAGScheduler: waiting: Set(ResultStage 123)\n",
      "22/11/29 14:39:52 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:39:52 INFO DAGScheduler: Submitting ResultStage 123 (ShuffledRDD[342] at reduceByKey at MulticlassMetrics.scala:61), which has no missing parents\n",
      "22/11/29 14:39:52 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 4.7 KiB, free 361.4 MiB)\n",
      "22/11/29 14:39:52 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 2.8 KiB, free 361.3 MiB)\n",
      "22/11/29 14:39:52 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 172.17.0.1:38511 (size: 2.8 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:39:52 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:39:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (ShuffledRDD[342] at reduceByKey at MulticlassMetrics.scala:61) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:39:52 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:39:52 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 117) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:39:52 INFO Executor: Running task 0.0 in stage 123.0 (TID 117)\n",
      "22/11/29 14:39:52 INFO ShuffleBlockFetcherIterator: Getting 1 (405.0 B) non-empty blocks including 1 (405.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:39:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms\n",
      "22/11/29 14:39:52 INFO Executor: Finished task 0.0 in stage 123.0 (TID 117). 1854 bytes result sent to driver\n",
      "22/11/29 14:39:52 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 117) in 14 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:39:52 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:39:52 INFO DAGScheduler: ResultStage 123 (collectAsMap at MulticlassMetrics.scala:61) finished in 0.020 s\n",
      "22/11/29 14:39:52 INFO DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:39:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 123: Stage finished\n",
      "22/11/29 14:39:52 INFO DAGScheduler: Job 97 finished: collectAsMap at MulticlassMetrics.scala:61, took 0.294418 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18942382496005106"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = MulticlassClassificationEvaluator(labelCol='label',predictionCol=\"prediction\")\n",
    "evaluation.evaluate(prediction.select(\"label\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "726068d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:48:03 INFO Instrumentation: [e7d237fe] Stage class: RandomForestClassifier\n",
      "22/11/29 14:48:03 INFO Instrumentation: [e7d237fe] Stage uid: RandomForestClassifier_93c04c4e6474\n",
      "22/11/29 14:48:03 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:48:03 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:48:03 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:48:03 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 350.3 KiB, free 361.0 MiB)\n",
      "22/11/29 14:48:03 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 361.0 MiB)\n",
      "22/11/29 14:48:03 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.7 MiB)\n",
      "22/11/29 14:48:03 INFO SparkContext: Created broadcast 227 from rdd at Instrumentation.scala:62\n",
      "22/11/29 14:48:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:48:03 INFO Instrumentation: [e7d237fe] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)\n",
      "22/11/29 14:48:03 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:48:03 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:48:03 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:48:04 INFO CodeGenerator: Code generated in 25.509221 ms\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 350.3 KiB, free 360.6 MiB)\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 360.6 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.7 MiB)\n",
      "22/11/29 14:48:04 INFO SparkContext: Created broadcast 228 from take at Classifier.scala:146\n",
      "22/11/29 14:48:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Registering RDD 352 (take at Classifier.scala:146) as input to shuffle 26\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Got map stage job 98 (take at Classifier.scala:146) with 1 output partitions\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Final stage: ShuffleMapStage 124 (take at Classifier.scala:146)\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[352] at take at Classifier.scala:146), which has no missing parents\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 37.0 KiB, free 360.6 MiB)\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 360.5 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 172.17.0.1:38511 (size: 17.2 KiB, free: 365.7 MiB)\n",
      "22/11/29 14:48:04 INFO SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[352] at take at Classifier.scala:146) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:04 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 118) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:04 INFO Executor: Running task 0.0 in stage 124.0 (TID 118)\n",
      "22/11/29 14:48:04 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:48:04 INFO Executor: Finished task 0.0 in stage 124.0 (TID 118). 2760 bytes result sent to driver\n",
      "22/11/29 14:48:04 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 118) in 159 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:04 INFO DAGScheduler: ShuffleMapStage 124 (take at Classifier.scala:146) finished in 0.170 s\n",
      "22/11/29 14:48:04 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:48:04 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:48:04 INFO DAGScheduler: waiting: Set()\n",
      "22/11/29 14:48:04 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:48:04 INFO CodeGenerator: Code generated in 17.389264 ms\n",
      "22/11/29 14:48:04 INFO SparkContext: Starting job: take at Classifier.scala:146\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Got job 99 (take at Classifier.scala:146) with 1 output partitions\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Final stage: ResultStage 126 (take at Classifier.scala:146)\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[355] at take at Classifier.scala:146), which has no missing parents\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 11.8 KiB, free 360.5 MiB)\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 360.5 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 172.17.0.1:38511 (size: 5.7 KiB, free: 365.7 MiB)\n",
      "22/11/29 14:48:04 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[355] at take at Classifier.scala:146) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:04 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 119) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:04 INFO Executor: Running task 0.0 in stage 126.0 (TID 119)\n",
      "22/11/29 14:48:04 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:48:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:48:04 INFO Executor: Finished task 0.0 in stage 126.0 (TID 119). 2650 bytes result sent to driver\n",
      "22/11/29 14:48:04 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 119) in 9 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:04 INFO DAGScheduler: ResultStage 126 (take at Classifier.scala:146) finished in 0.013 s\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Job 99 finished: take at Classifier.scala:146, took 0.016053 s\n",
      "22/11/29 14:48:04 INFO CodeGenerator: Code generated in 11.717161 ms\n",
      "22/11/29 14:48:04 INFO RandomForestClassifier: org.apache.spark.ml.classification.RandomForestClassifier inferred 5 classes for labelCol=RandomForestClassifier_93c04c4e6474__labelCol since numClasses was not specified in the column metadata.\n",
      "22/11/29 14:48:04 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:48:04 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:48:04 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 172.17.0.1:38511 in memory (size: 34.1 KiB, free: 365.7 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 172.17.0.1:38511 in memory (size: 34.1 KiB, free: 365.7 MiB)\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 350.3 KiB, free 360.9 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 172.17.0.1:38511 in memory (size: 5.7 KiB, free: 365.7 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 172.17.0.1:38511 in memory (size: 34.1 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 172.17.0.1:38511 in memory (size: 17.2 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 361.3 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:04 INFO SparkContext: Created broadcast 231 from rdd at Predictor.scala:81\n",
      "22/11/29 14:48:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 172.17.0.1:38511 in memory (size: 26.9 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 172.17.0.1:38511 in memory (size: 34.1 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 172.17.0.1:38511 in memory (size: 2.8 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 172.17.0.1:38511 in memory (size: 26.9 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 172.17.0.1:38511 in memory (size: 29.2 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:48:04 INFO Instrumentation: [e7d237fe] {}\n",
      "22/11/29 14:48:04 INFO SparkContext: Starting job: take at DecisionTreeMetadata.scala:119\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Got job 100 (take at DecisionTreeMetadata.scala:119) with 1 output partitions\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Final stage: ResultStage 127 (take at DecisionTreeMetadata.scala:119)\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[365] at map at DecisionTreeMetadata.scala:119), which has no missing parents\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 53.9 KiB, free 361.9 MiB)\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 22.6 KiB, free 361.9 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 172.17.0.1:38511 (size: 22.6 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:48:04 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[365] at map at DecisionTreeMetadata.scala:119) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:04 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 120) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:04 INFO Executor: Running task 0.0 in stage 127.0 (TID 120)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:48:04 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:48:04 INFO Executor: Finished task 0.0 in stage 127.0 (TID 120). 1798 bytes result sent to driver\n",
      "22/11/29 14:48:04 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 120) in 148 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:04 INFO DAGScheduler: ResultStage 127 (take at DecisionTreeMetadata.scala:119) finished in 0.155 s\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 127: Stage finished\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Job 100 finished: take at DecisionTreeMetadata.scala:119, took 0.157770 s\n",
      "22/11/29 14:48:04 INFO SparkContext: Starting job: aggregate at DecisionTreeMetadata.scala:125\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Got job 101 (aggregate at DecisionTreeMetadata.scala:125) with 1 output partitions\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Final stage: ResultStage 128 (aggregate at DecisionTreeMetadata.scala:125)\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[364] at retag at RandomForest.scala:274), which has no missing parents\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 53.9 KiB, free 361.9 MiB)\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 22.7 KiB, free 361.9 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 172.17.0.1:38511 (size: 22.7 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:04 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[364] at retag at RandomForest.scala:274) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:04 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 121) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:04 INFO Executor: Running task 0.0 in stage 128.0 (TID 121)\n",
      "22/11/29 14:48:04 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:48:04 INFO Executor: Finished task 0.0 in stage 128.0 (TID 121). 1913 bytes result sent to driver\n",
      "22/11/29 14:48:04 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 121) in 188 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:04 INFO DAGScheduler: ResultStage 128 (aggregate at DecisionTreeMetadata.scala:125) finished in 0.195 s\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 128: Stage finished\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Job 101 finished: aggregate at DecisionTreeMetadata.scala:125, took 0.199021 s\n",
      "22/11/29 14:48:04 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:1054\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Registering RDD 367 (flatMap at RandomForest.scala:1039) as input to shuffle 27\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Got job 102 (collectAsMap at RandomForest.scala:1054) with 1 output partitions\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Final stage: ResultStage 130 (collectAsMap at RandomForest.scala:1054)\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 129)\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 129)\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting ShuffleMapStage 129 (MapPartitionsRDD[367] at flatMap at RandomForest.scala:1039), which has no missing parents\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 58.0 KiB, free 361.8 MiB)\n",
      "22/11/29 14:48:04 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 24.2 KiB, free 361.8 MiB)\n",
      "22/11/29 14:48:04 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 172.17.0.1:38511 (size: 24.2 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:04 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 129 (MapPartitionsRDD[367] at flatMap at RandomForest.scala:1039) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:04 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:04 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 122) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:04 INFO Executor: Running task 0.0 in stage 129.0 (TID 122)\n",
      "22/11/29 14:48:05 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:48:05 INFO Executor: Finished task 0.0 in stage 129.0 (TID 122). 2090 bytes result sent to driver\n",
      "22/11/29 14:48:05 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 122) in 400 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:05 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:05 INFO DAGScheduler: ShuffleMapStage 129 (flatMap at RandomForest.scala:1039) finished in 0.406 s\n",
      "22/11/29 14:48:05 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:48:05 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:48:05 INFO DAGScheduler: waiting: Set(ResultStage 130)\n",
      "22/11/29 14:48:05 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[369] at map at RandomForest.scala:1054), which has no missing parents\n",
      "22/11/29 14:48:05 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 9.8 KiB, free 361.8 MiB)\n",
      "22/11/29 14:48:05 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 361.8 MiB)\n",
      "22/11/29 14:48:05 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 172.17.0.1:38511 (size: 4.5 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:05 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[369] at map at RandomForest.scala:1054) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:05 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:05 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 123) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:05 INFO Executor: Running task 0.0 in stage 130.0 (TID 123)\n",
      "22/11/29 14:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 (109.5 KiB) non-empty blocks including 1 (109.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:48:05 INFO Executor: Finished task 0.0 in stage 130.0 (TID 123). 4125 bytes result sent to driver\n",
      "22/11/29 14:48:05 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 123) in 83 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:05 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:05 INFO DAGScheduler: ResultStage 130 (collectAsMap at RandomForest.scala:1054) finished in 0.089 s\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 130: Stage finished\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Job 102 finished: collectAsMap at RandomForest.scala:1054, took 0.500076 s\n",
      "22/11/29 14:48:05 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 3.8 KiB, free 361.8 MiB)\n",
      "22/11/29 14:48:05 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 1471.0 B, free 361.8 MiB)\n",
      "22/11/29 14:48:05 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 172.17.0.1:38511 (size: 1471.0 B, free: 365.8 MiB)\n",
      "22/11/29 14:48:05 INFO SparkContext: Created broadcast 236 from broadcast at RandomForest.scala:293\n",
      "22/11/29 14:48:05 INFO Instrumentation: [e7d237fe] {\"numFeatures\":6}\n",
      "22/11/29 14:48:05 INFO Instrumentation: [e7d237fe] {\"numClasses\":5}\n",
      "22/11/29 14:48:05 INFO Instrumentation: [e7d237fe] {\"numExamples\":8550}\n",
      "22/11/29 14:48:05 INFO Instrumentation: [e7d237fe] {\"sumOfWeights\":8550.0}\n",
      "22/11/29 14:48:05 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 2.2 KiB, free 361.8 MiB)\n",
      "22/11/29 14:48:05 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 511.0 B, free 361.7 MiB)\n",
      "22/11/29 14:48:05 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 172.17.0.1:38511 (size: 511.0 B, free: 365.8 MiB)\n",
      "22/11/29 14:48:05 INFO SparkContext: Created broadcast 237 from broadcast at RandomForest.scala:622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:48:05 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Registering RDD 372 (mapPartitions at RandomForest.scala:644) as input to shuffle 28\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Got job 103 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Final stage: ResultStage 132 (collectAsMap at RandomForest.scala:663)\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 131)\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 131)\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[372] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "22/11/29 14:48:05 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 60.6 KiB, free 361.7 MiB)\n",
      "22/11/29 14:48:05 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 26.1 KiB, free 361.7 MiB)\n",
      "22/11/29 14:48:05 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 172.17.0.1:38511 (size: 26.1 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:05 INFO SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[372] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:05 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:05 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 124) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:05 INFO Executor: Running task 0.0 in stage 131.0 (TID 124)\n",
      "22/11/29 14:48:05 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 172.17.0.1:38511 in memory (size: 22.6 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:05 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 172.17.0.1:38511 in memory (size: 22.7 KiB, free: 365.8 MiB)\n",
      "22/11/29 14:48:05 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 172.17.0.1:38511 in memory (size: 34.1 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:48:05 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 172.17.0.1:38511 in memory (size: 24.2 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:48:05 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 172.17.0.1:38511 in memory (size: 4.5 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:48:05 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block rdd_371_0 stored as values in memory (estimated size 1693.6 KiB, free 360.6 MiB)\n",
      "22/11/29 14:48:06 INFO BlockManagerInfo: Added rdd_371_0 in memory on 172.17.0.1:38511 (size: 1693.6 KiB, free: 364.2 MiB)\n",
      "22/11/29 14:48:06 INFO Executor: Finished task 0.0 in stage 131.0 (TID 124). 2133 bytes result sent to driver\n",
      "22/11/29 14:48:06 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 124) in 555 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:06 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:06 INFO DAGScheduler: ShuffleMapStage 131 (mapPartitions at RandomForest.scala:644) finished in 0.568 s\n",
      "22/11/29 14:48:06 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:48:06 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:48:06 INFO DAGScheduler: waiting: Set(ResultStage 132)\n",
      "22/11/29 14:48:06 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[374] at map at RandomForest.scala:663), which has no missing parents\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 7.4 KiB, free 360.6 MiB)\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 360.6 MiB)\n",
      "22/11/29 14:48:06 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 172.17.0.1:38511 (size: 3.8 KiB, free: 364.2 MiB)\n",
      "22/11/29 14:48:06 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[374] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:06 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:06 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 125) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:06 INFO Executor: Running task 0.0 in stage 132.0 (TID 125)\n",
      "22/11/29 14:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (28.8 KiB) non-empty blocks including 1 (28.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 131:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:48:06 INFO Executor: Finished task 0.0 in stage 132.0 (TID 125). 6833 bytes result sent to driver\n",
      "22/11/29 14:48:06 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 125) in 321 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:06 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:06 INFO DAGScheduler: ResultStage 132 (collectAsMap at RandomForest.scala:663) finished in 0.329 s\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 132: Stage finished\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Job 103 finished: collectAsMap at RandomForest.scala:663, took 0.903964 s\n",
      "22/11/29 14:48:06 INFO TorrentBroadcast: Destroying Broadcast(237) (from destroy at RandomForest.scala:674)\n",
      "22/11/29 14:48:06 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 172.17.0.1:38511 in memory (size: 511.0 B, free: 364.2 MiB)\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_240 stored as values in memory (estimated size 4.0 KiB, free 360.6 MiB)\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 681.0 B, free 360.6 MiB)\n",
      "22/11/29 14:48:06 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 172.17.0.1:38511 (size: 681.0 B, free: 364.2 MiB)\n",
      "22/11/29 14:48:06 INFO SparkContext: Created broadcast 240 from broadcast at RandomForest.scala:622\n",
      "22/11/29 14:48:06 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Registering RDD 375 (mapPartitions at RandomForest.scala:644) as input to shuffle 29\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Got job 104 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Final stage: ResultStage 134 (collectAsMap at RandomForest.scala:663)\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 133)\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 133)\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Submitting ShuffleMapStage 133 (MapPartitionsRDD[375] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_241 stored as values in memory (estimated size 68.2 KiB, free 360.6 MiB)\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 360.5 MiB)\n",
      "22/11/29 14:48:06 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 172.17.0.1:38511 (size: 29.5 KiB, free: 364.2 MiB)\n",
      "22/11/29 14:48:06 INFO SparkContext: Created broadcast 241 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 133 (MapPartitionsRDD[375] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:06 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:06 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 126) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:06 INFO Executor: Running task 0.0 in stage 133.0 (TID 126)\n",
      "22/11/29 14:48:06 INFO BlockManager: Found block rdd_371_0 locally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:48:06 INFO Executor: Finished task 0.0 in stage 133.0 (TID 126). 2090 bytes result sent to driver\n",
      "22/11/29 14:48:06 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 126) in 391 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:06 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:06 INFO DAGScheduler: ShuffleMapStage 133 (mapPartitions at RandomForest.scala:644) finished in 0.397 s\n",
      "22/11/29 14:48:06 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:48:06 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:48:06 INFO DAGScheduler: waiting: Set(ResultStage 134)\n",
      "22/11/29 14:48:06 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[377] at map at RandomForest.scala:663), which has no missing parents\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_242 stored as values in memory (estimated size 11.1 KiB, free 360.5 MiB)\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 360.5 MiB)\n",
      "22/11/29 14:48:06 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 172.17.0.1:38511 (size: 5.3 KiB, free: 364.2 MiB)\n",
      "22/11/29 14:48:06 INFO SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[377] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:06 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:06 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 127) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:06 INFO Executor: Running task 0.0 in stage 134.0 (TID 127)\n",
      "22/11/29 14:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 (31.7 KiB) non-empty blocks including 1 (31.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:48:06 INFO Executor: Finished task 0.0 in stage 134.0 (TID 127). 10071 bytes result sent to driver\n",
      "22/11/29 14:48:06 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 127) in 39 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:06 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:06 INFO DAGScheduler: ResultStage 134 (collectAsMap at RandomForest.scala:663) finished in 0.050 s\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 134: Stage finished\n",
      "22/11/29 14:48:06 INFO DAGScheduler: Job 104 finished: collectAsMap at RandomForest.scala:663, took 0.452062 s\n",
      "22/11/29 14:48:06 INFO TorrentBroadcast: Destroying Broadcast(240) (from destroy at RandomForest.scala:674)\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_243 stored as values in memory (estimated size 7.1 KiB, free 360.5 MiB)\n",
      "22/11/29 14:48:06 INFO MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 937.0 B, free 360.5 MiB)\n",
      "22/11/29 14:48:06 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 172.17.0.1:38511 (size: 937.0 B, free: 364.2 MiB)\n",
      "22/11/29 14:48:06 INFO SparkContext: Created broadcast 243 from broadcast at RandomForest.scala:622\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_240_piece0 on 172.17.0.1:38511 in memory (size: 681.0 B, free: 364.2 MiB)\n",
      "22/11/29 14:48:07 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Registering RDD 378 (mapPartitions at RandomForest.scala:644) as input to shuffle 30\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Got job 105 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Final stage: ResultStage 136 (collectAsMap at RandomForest.scala:663)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 135)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 135)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting ShuffleMapStage 135 (MapPartitionsRDD[378] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_244 stored as values in memory (estimated size 79.0 KiB, free 360.4 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 33.0 KiB, free 360.4 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 172.17.0.1:38511 (size: 33.0 KiB, free: 364.2 MiB)\n",
      "22/11/29 14:48:07 INFO SparkContext: Created broadcast 244 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 135 (MapPartitionsRDD[378] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 128) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:07 INFO Executor: Running task 0.0 in stage 135.0 (TID 128)\n",
      "22/11/29 14:48:07 INFO BlockManager: Found block rdd_371_0 locally\n",
      "22/11/29 14:48:07 INFO Executor: Finished task 0.0 in stage 135.0 (TID 128). 2090 bytes result sent to driver\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 128) in 181 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:07 INFO DAGScheduler: ShuffleMapStage 135 (mapPartitions at RandomForest.scala:644) finished in 0.195 s\n",
      "22/11/29 14:48:07 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:48:07 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:48:07 INFO DAGScheduler: waiting: Set(ResultStage 136)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[380] at map at RandomForest.scala:663), which has no missing parents\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_245 stored as values in memory (estimated size 13.8 KiB, free 360.4 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 360.4 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 172.17.0.1:38511 (size: 6.1 KiB, free: 364.2 MiB)\n",
      "22/11/29 14:48:07 INFO SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[380] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 129) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:07 INFO Executor: Running task 0.0 in stage 136.0 (TID 129)\n",
      "22/11/29 14:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (34.9 KiB) non-empty blocks including 1 (34.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:48:07 INFO Executor: Finished task 0.0 in stage 136.0 (TID 129). 15326 bytes result sent to driver\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 129) in 47 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:07 INFO DAGScheduler: ResultStage 136 (collectAsMap at RandomForest.scala:663) finished in 0.053 s\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Job 105 finished: collectAsMap at RandomForest.scala:663, took 0.251845 s\n",
      "22/11/29 14:48:07 INFO TorrentBroadcast: Destroying Broadcast(243) (from destroy at RandomForest.scala:674)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_243_piece0 on 172.17.0.1:38511 in memory (size: 937.0 B, free: 364.2 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_246 stored as values in memory (estimated size 11.0 KiB, free 360.4 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 1304.0 B, free 360.4 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 172.17.0.1:38511 (size: 1304.0 B, free: 364.2 MiB)\n",
      "22/11/29 14:48:07 INFO SparkContext: Created broadcast 246 from broadcast at RandomForest.scala:622\n",
      "22/11/29 14:48:07 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Registering RDD 381 (mapPartitions at RandomForest.scala:644) as input to shuffle 31\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Got job 106 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Final stage: ResultStage 138 (collectAsMap at RandomForest.scala:663)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 137)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 137)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting ShuffleMapStage 137 (MapPartitionsRDD[381] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_247 stored as values in memory (estimated size 96.3 KiB, free 360.3 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 38.4 KiB, free 360.2 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 172.17.0.1:38511 (size: 38.4 KiB, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 137 (MapPartitionsRDD[381] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Adding task set 137.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 130) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:07 INFO Executor: Running task 0.0 in stage 137.0 (TID 130)\n",
      "22/11/29 14:48:07 INFO BlockManager: Found block rdd_371_0 locally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:48:07 INFO Executor: Finished task 0.0 in stage 137.0 (TID 130). 2090 bytes result sent to driver\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 130) in 131 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:07 INFO DAGScheduler: ShuffleMapStage 137 (mapPartitions at RandomForest.scala:644) finished in 0.141 s\n",
      "22/11/29 14:48:07 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:48:07 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:48:07 INFO DAGScheduler: waiting: Set(ResultStage 138)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[383] at map at RandomForest.scala:663), which has no missing parents\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_248 stored as values in memory (estimated size 17.6 KiB, free 360.2 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 360.2 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 172.17.0.1:38511 (size: 7.1 KiB, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO SparkContext: Created broadcast 248 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[383] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 131) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:07 INFO Executor: Running task 0.0 in stage 138.0 (TID 131)\n",
      "22/11/29 14:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (42.2 KiB) non-empty blocks including 1 (42.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:48:07 INFO Executor: Finished task 0.0 in stage 138.0 (TID 131). 22026 bytes result sent to driver\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 131) in 68 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:07 INFO DAGScheduler: ResultStage 138 (collectAsMap at RandomForest.scala:663) finished in 0.073 s\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 138: Stage finished\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Job 106 finished: collectAsMap at RandomForest.scala:663, took 0.220301 s\n",
      "22/11/29 14:48:07 INFO TorrentBroadcast: Destroying Broadcast(246) (from destroy at RandomForest.scala:674)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_246_piece0 on 172.17.0.1:38511 in memory (size: 1304.0 B, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_249 stored as values in memory (estimated size 17.0 KiB, free 360.2 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 1806.0 B, free 360.2 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 172.17.0.1:38511 (size: 1806.0 B, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO SparkContext: Created broadcast 249 from broadcast at RandomForest.scala:622\n",
      "22/11/29 14:48:07 INFO SparkContext: Starting job: collectAsMap at RandomForest.scala:663\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Registering RDD 384 (mapPartitions at RandomForest.scala:644) as input to shuffle 32\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Got job 107 (collectAsMap at RandomForest.scala:663) with 1 output partitions\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Final stage: ResultStage 140 (collectAsMap at RandomForest.scala:663)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 139)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 139)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting ShuffleMapStage 139 (MapPartitionsRDD[384] at mapPartitions at RandomForest.scala:644), which has no missing parents\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_250 stored as values in memory (estimated size 121.3 KiB, free 360.1 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 46.5 KiB, free 360.0 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 172.17.0.1:38511 (size: 46.5 KiB, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO SparkContext: Created broadcast 250 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 139 (MapPartitionsRDD[384] at mapPartitions at RandomForest.scala:644) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 132) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5015 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:07 INFO Executor: Running task 0.0 in stage 139.0 (TID 132)\n",
      "22/11/29 14:48:07 INFO BlockManager: Found block rdd_371_0 locally\n",
      "22/11/29 14:48:07 INFO Executor: Finished task 0.0 in stage 139.0 (TID 132). 2090 bytes result sent to driver\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 132) in 133 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:07 INFO DAGScheduler: ShuffleMapStage 139 (mapPartitions at RandomForest.scala:644) finished in 0.146 s\n",
      "22/11/29 14:48:07 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/11/29 14:48:07 INFO DAGScheduler: running: Set()\n",
      "22/11/29 14:48:07 INFO DAGScheduler: waiting: Set(ResultStage 140)\n",
      "22/11/29 14:48:07 INFO DAGScheduler: failed: Set()\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[386] at map at RandomForest.scala:663), which has no missing parents\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_251 stored as values in memory (estimated size 23.2 KiB, free 360.0 MiB)\n",
      "22/11/29 14:48:07 INFO MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 360.0 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 172.17.0.1:38511 (size: 8.7 KiB, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[386] at map at RandomForest.scala:663) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 133) (172.17.0.1, executor driver, partition 0, NODE_LOCAL, 4271 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:07 INFO Executor: Running task 0.0 in stage 140.0 (TID 133)\n",
      "22/11/29 14:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 (56.2 KiB) non-empty blocks including 1 (56.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "22/11/29 14:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 172.17.0.1:38511 in memory (size: 26.1 KiB, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO Executor: Finished task 0.0 in stage 140.0 (TID 133). 33992 bytes result sent to driver\n",
      "22/11/29 14:48:07 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 133) in 99 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:07 INFO DAGScheduler: ResultStage 140 (collectAsMap at RandomForest.scala:663) finished in 0.105 s\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 140: Stage finished\n",
      "22/11/29 14:48:07 INFO DAGScheduler: Job 107 finished: collectAsMap at RandomForest.scala:663, took 0.254473 s\n",
      "22/11/29 14:48:07 INFO TorrentBroadcast: Destroying Broadcast(249) (from destroy at RandomForest.scala:674)\n",
      "22/11/29 14:48:07 INFO RandomForest: Internal timing for DecisionTree:\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_249_piece0 on 172.17.0.1:38511 in memory (size: 1806.0 B, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO RandomForest:   init: 0.011041542\n",
      "  total: 2.366397218\n",
      "  findBestSplits: 2.340418781\n",
      "  chooseSplits: 2.31894421\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_242_piece0 on 172.17.0.1:38511 in memory (size: 5.3 KiB, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_244_piece0 on 172.17.0.1:38511 in memory (size: 33.0 KiB, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_248_piece0 on 172.17.0.1:38511 in memory (size: 7.1 KiB, free: 364.1 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_250_piece0 on 172.17.0.1:38511 in memory (size: 46.5 KiB, free: 364.2 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_245_piece0 on 172.17.0.1:38511 in memory (size: 6.1 KiB, free: 364.2 MiB)\n",
      "22/11/29 14:48:07 INFO MapPartitionsRDD: Removing RDD 371 from persistence list\n",
      "22/11/29 14:48:07 INFO TorrentBroadcast: Destroying Broadcast(236) (from destroy at RandomForest.scala:305)\n",
      "22/11/29 14:48:07 INFO BlockManager: Removing RDD 371\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 172.17.0.1:38511 in memory (size: 1471.0 B, free: 365.8 MiB)\n",
      "22/11/29 14:48:07 INFO Instrumentation: [e7d237fe] {\"numClasses\":5}\n",
      "22/11/29 14:48:07 INFO Instrumentation: [e7d237fe] {\"numFeatures\":6}\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_247_piece0 on 172.17.0.1:38511 in memory (size: 38.4 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_241_piece0 on 172.17.0.1:38511 in memory (size: 29.5 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:48:07 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 172.17.0.1:38511 in memory (size: 3.8 KiB, free: 365.9 MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:48:08 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:48:08 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:48:08 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:48:08 INFO MemoryStore: Block broadcast_252 stored as values in memory (estimated size 350.3 KiB, free 362.0 MiB)\n",
      "22/11/29 14:48:08 INFO MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 362.0 MiB)\n",
      "22/11/29 14:48:08 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 365.9 MiB)\n",
      "22/11/29 14:48:08 INFO SparkContext: Created broadcast 252 from rdd at ClassificationSummary.scala:58\n",
      "22/11/29 14:48:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:48:08 INFO Instrumentation: [e7d237fe] training finished\n"
     ]
    }
   ],
   "source": [
    "randModel = ranPipeline.fit(train_c)\n",
    "prediction_rand  = randModel.transform(test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f916826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 14:48:28 INFO FileSourceStrategy: Pushed Filters: \n",
      "22/11/29 14:48:28 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "22/11/29 14:48:28 INFO FileSourceStrategy: Output Data Schema: struct<Restaurant_latitude: double, Restaurant_longitude: double, Delivery_location_latitude: double, Delivery_location_longitude: double, Weather_idx: double ... 5 more fields>\n",
      "22/11/29 14:48:28 INFO CodeGenerator: Code generated in 35.226193 ms\n",
      "22/11/29 14:48:28 INFO MemoryStore: Block broadcast_253 stored as values in memory (estimated size 350.3 KiB, free 364.8 MiB)\n",
      "22/11/29 14:48:28 INFO MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 34.1 KiB, free 364.8 MiB)\n",
      "22/11/29 14:48:28 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 172.17.0.1:38511 (size: 34.1 KiB, free: 366.2 MiB)\n",
      "22/11/29 14:48:28 INFO SparkContext: Created broadcast 253 from showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 14:48:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "22/11/29 14:48:28 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "22/11/29 14:48:28 INFO DAGScheduler: Got job 108 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "22/11/29 14:48:28 INFO DAGScheduler: Final stage: ResultStage 141 (showString at NativeMethodAccessorImpl.java:0)\n",
      "22/11/29 14:48:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/11/29 14:48:28 INFO DAGScheduler: Missing parents: List()\n",
      "22/11/29 14:48:28 INFO DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[397] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "22/11/29 14:48:28 INFO MemoryStore: Block broadcast_254 stored as values in memory (estimated size 140.1 KiB, free 364.7 MiB)\n",
      "22/11/29 14:48:28 INFO MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 55.6 KiB, free 364.6 MiB)\n",
      "22/11/29 14:48:28 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 172.17.0.1:38511 (size: 55.6 KiB, free: 366.1 MiB)\n",
      "22/11/29 14:48:28 INFO SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:1513\n",
      "22/11/29 14:48:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[397] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "22/11/29 14:48:28 INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks resource profile 0\n",
      "22/11/29 14:48:28 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 134) (172.17.0.1, executor driver, partition 0, PROCESS_LOCAL, 5026 bytes) taskResourceAssignments Map()\n",
      "22/11/29 14:48:28 INFO Executor: Running task 0.0 in stage 141.0 (TID 134)\n",
      "22/11/29 14:48:28 INFO FileScanRDD: Reading File path: file:///run/media/solverbot/repoA/gitFolders/dashBoard%20Designs/externalData/amazonRA_encoded.csv/part-00000-6df05801-2b9a-4d6c-9a42-0d8304d1f37f-c000.csv, range: 0-1273099, partition values: [empty row]\n",
      "22/11/29 14:48:28 INFO Executor: Finished task 0.0 in stage 141.0 (TID 134). 2021 bytes result sent to driver\n",
      "22/11/29 14:48:28 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 134) in 182 ms on 172.17.0.1 (executor driver) (1/1)\n",
      "22/11/29 14:48:28 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool \n",
      "22/11/29 14:48:28 INFO DAGScheduler: ResultStage 141 (showString at NativeMethodAccessorImpl.java:0) finished in 0.191 s\n",
      "22/11/29 14:48:28 INFO DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/11/29 14:48:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 141: Stage finished\n",
      "22/11/29 14:48:28 INFO DAGScheduler: Job 108 finished: showString at NativeMethodAccessorImpl.java:0, took 0.193737 s\n",
      "22/11/29 14:48:28 INFO CodeGenerator: Code generated in 12.017141 ms\n",
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_rand.select(\"label\",\"prediction\").show(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
